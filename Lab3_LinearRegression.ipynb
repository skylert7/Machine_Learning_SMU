{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3_Final_No_Explanations.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kIiw4du-dqJi",
        "l5eIc3UFe5JW",
        "nnj2zFITe_JQ",
        "UyN4seKac8uT",
        "IfE5cSb6c8uY",
        "5HM7vP1Ec8ui"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrBk4qCIiQZq",
        "colab_type": "text"
      },
      "source": [
        "### Taylor Slaton\n",
        "### Skyler Tran"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ND8kn4Bzc96I",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.special import expit\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore', DeprecationWarning)\n",
        "%matplotlib inline \n",
        "\n",
        "# upload data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8v9FT2Kc8t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read in data\n",
        "original_data = pd.read_csv('./clinvar-conflicting/clinvar_conflicting.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "357d2-rYc8t_",
        "colab_type": "code",
        "outputId": "81dbf672-4c51-4d0b-884c-2a6149d46cbe",
        "colab": {}
      },
      "source": [
        "# Data summary\n",
        "print(original_data.dtypes)\n",
        "print('===========')\n",
        "# print(data.info())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REF            object\n",
            "ALT            object\n",
            "AF_EXAC       float64\n",
            "AF_TGP        float64\n",
            "ORIGIN        float64\n",
            "CLASS           int64\n",
            "IMPACT         object\n",
            "EXON           object\n",
            "SIFT           object\n",
            "PolyPhen       object\n",
            "CADD_PHRED    float64\n",
            "CADD_RAW      float64\n",
            "dtype: object\n",
            "===========\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tvc2VCdNdX5o"
      },
      "source": [
        "# Lab 3 : Extending Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hHhmQLG3dhxK"
      },
      "source": [
        "## Dataset Selection\n",
        "\n",
        "Select a dataset identically to the way you selected for the lab one (i.e., table data). You are not required to use the same dataset that you used in the past, but you are encouraged. You must identify a classification task from the dataset that contains three or more classes to predict. That is it cannot be a binary classification; it must be multi-class prediction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kIiw4du-dqJi"
      },
      "source": [
        "## Preparation and Overview [***30 points***]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l5eIc3UFe5JW"
      },
      "source": [
        "### ***20 points***\n",
        "Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or use mostly for offline analysis? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iS7BczUpfWR0"
      },
      "source": [
        "*Explain answer here*\n",
        "\n",
        "The Genetic Variant Classifications dataset is a dataset that contains information on whether labs have classified different genetic variants in different ways. Variants are classified by clinical laboratories on whether a variant is considered benign, likely benign, uncertain, likely pathogenic, or pathogenic. This is how these classifications come to be, but it is possible that different labs will classify variants differently. When the difference is between benign and likely benign or pathogenic and likely pathogenic, the difference isn't that significant. However, when the differences are between benign or pathogenic the issue is much larger. This dataset takes this data and compiles whether or not these clinical labs have identified these variants differently. This is a problem that causes clinicians and researches to not necessarily know how to give a patient advice or how to continue with the found variant. This can cause a mix of false positives and significantly more problematic false negatives. <br> \n",
        "Our plan for this data set is to find a way to show people if their genetic variant falls within this gray area to be able seek a second opinion to keep themselves safe. This can also affect medical professionals, as they may be looking at conflicting data and not know what to tell their patient. <br />\n",
        "\n",
        "Our classification goal is to train a dataset on the patterns of conflicting classifications from different labs, as well as those that do not conflict. We will also be looking at the proteins and the allele patterns to see what is most likely pathogenic and what is most likely benign. The goal is to make an algorithm that medical professionals can use to be able to see what labs to listen to and what a genetic variant is classified more as, so that they can give their patients the proper information for their health, and if they should seek more opinions.\n",
        "<br />\n",
        "This model would be used for offline analysis. The algorithm would run on the database and end with some form of chart or graph that a medical professional could look at when dealing with a certain genetic variant. The medical professional would not plug in a variant and wait, as the data is already collected. This system would run and then whatever data was found would be used by the medical professional from then on, until more lab results are added to the database and the algorithm is run again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nnj2zFITe_JQ"
      },
      "source": [
        "### ***5 points***\n",
        " (mostly the same processes as from previous labs) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uk3POI9AfsaB"
      },
      "source": [
        "*Explain answer here*\n",
        "\n",
        "| Name               | Type     | Level of<br>Measurement                                                   | Possibilities                                                                                                                                            | Explanation                                                                                                                                                                                                          | Kept? |\n",
        "|--------------------|----------|---------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------|\n",
        "| CHROM              | object   | Ordinal*<br>* Chromosomes<br>are <br>recognized<br>in a specific<br>order | Between 1 and 22                                                                                                                                         | Chromosome the variant is located on                                                                                                                                                                                 | No    |\n",
        "| POS                | int 64   | Interval                                                                  | Between 961 and 248                                                                                                                                      | Position on the chromosome the variant<br> is located on                                                                                                                                                             | No    |\n",
        "| REF                | object   | Nominal                                                                   | a, c, t, g                                                                                                                                               | Reference Allele                                                                                                                                                                                                     | Yes   |\n",
        "| ALT                | object   | Nominal                                                                   | a, c, t, g                                                                                                                                               | Alternate Allele                                                                                                                                                                                                     | Yes   |\n",
        "| AF_ESP             | float 64 | Interval                                                                  | Between 0 and 0.5                                                                                                                                        | Allele frequencies from GO-ESP                                                                                                                                                                                       | No    |\n",
        "| AF_EXAC            | float 64 | Interval                                                                  | Between 0 and 0.5                                                                                                                                        | Allele frequencies from ExAC                                                                                                                                                                                         | Yes   |\n",
        "| AF_TGP             | float 64 | Interval                                                                  | Between 0 and 0.5                                                                                                                                        | Allele frequencies from the 1000<br> genomes project                                                                                                                                                                 | Yes   |\n",
        "| CLNDISDB           | object   | Nominal                                                                   | Formula:<br>  OMIM:NNNNNN                                                                                                                                | Tag-value pairs of disease database<br> name and identifier                                                                                                                                                          | No    |\n",
        "| CLNDISDBINCL       | object   | Nominal                                                                   | Formula:<br>  OMIM:NNNNNN                                                                                                                                | Tag-value pairs of disease database<br> name and identifier for included <br> variant                                                                                                                                | No    |\n",
        "| CLNDN              | object   | Nominal                                                                   | Strings representing<br> a name                                                                                                                          | ClinVar's preferred disease name<br> for the concept specified by <br> disease identifiers in CLNDISDB                                                                                                               | No    |\n",
        "| CLNDNINCL          | object   | Nominal                                                                   | null                                                                                                                                                     | ClinVar's preferred disease name<br> for the concept specified by <br> disease identifiers in CLNDISDB<br> for included variant                                                                                      | No    |\n",
        "| CLNHGVS            | object   | Nominal                                                                   | Unique values                                                                                                                                            | Top-level HGVS* expression<br>* A standard made for describing<br>  variants, mutations, or <br>  polymorphisms                                                                                                      | No    |\n",
        "| CLNSIGINCL         | object   | Nominal                                                                   | Formula<br> VariationID:clinical significance                                                                                                            | Clinical significance for a<br> haplotype* or genotype* that<br> includes this variant<br>* Group of genes within an<br>  organism inherited from<br>  a single parent<br>* An organism's genetic <br>  constitution | No    |\n",
        "| CLNVC              | object   | Nominal                                                                   | single_nucleotide_variant<br>deletion                                                                                                                    | Variant Type                                                                                                                                                                                                         | No    |\n",
        "| CLNVI              | object   | Nominal                                                                   | Formula<br> UniProtKB_(protein):LNNNNN                                                                                                                   | Variant's clinical sources reported<br> as tag-value pairs of database and <br> variant identifier                                                                                                                   | No    |\n",
        "| MC                 | object   | Nominal                                                                   | Formula<br> SO:NNNNNNN|molecular_consequence                                                                                                             | Coma separated list of molecular<br> consequences in the form of <br> Sequence Ontology*<br>* A way to define sequence features                                                                                      | No    |\n",
        "| ORIGIN             | float 64 | Nominal                                                                   | unknown<br>germline<br>somatic<br>inherited<br>paternal<br>maternal<br>denovo<br>biparental<br>uniparental<br>not-tested<br>tested-inconclusive<br>other | Allele Origin                                                                                                                                                                                                        | Yes   |\n",
        "| SSR                | float 64 | Nominal                                                                   | 0 - unspecified<br>1 - Paralog<br>2 - byEST<br>4 - oldAlign<br>8 - Para_EST<br>16 - 1kg_failed<br>1024 - other                                           | Variant Suspect Reason Codes                                                                                                                                                                                         | No    |\n",
        "| CLASS              | int 64   | Nominal                                                                   | 0 - no conflict<br>1 - conflict                                                                                                                          | Binary representation of the target<br> class                                                                                                                                                                        | Yes   |\n",
        "| Allele             | object   | Nominal                                                                   | a, c, t, g                                                                                                                                               | Variant allele used to calculate the<br> consequence                                                                                                                                                                 | No    |\n",
        "| Consequences       | object   | Nominal                                                                   | 48 different values                                                                                                                                      | Type of consequence                                                                                                                                                                                                  | No    |\n",
        "| IMPACT             | object   | Ordinal                                                                   | LOW<br>MODERATE<br>MODIFIER                                                                                                                              | The impact modifier for the consequence<br> type                                                                                                                                                                     | Yes   |\n",
        "| SYMBOL             | object   | Nominal                                                                   | 2329 different values                                                                                                                                    | Gene Name                                                                                                                                                                                                            | No    |\n",
        "| Feature_type       | object   | Nominal                                                                   | Transcript<br>RegulatoryFeature<br>MotifFeature                                                                                                          | Type of feature                                                                                                                                                                                                      | No    |\n",
        "| Feature            | object   | Nominal                                                                   | Formula<br> LL_NNNNNN.N<br> *Differing number of N                                                                                                       | Ensemble stable ID of feature                                                                                                                                                                                        | No    |\n",
        "| BIOTYPE            | object   | Nominal                                                                   | protein_coding                                                                                                                                           | Biotype of transcript or regulatory<br> feature                                                                                                                                                                      | No    |\n",
        "| EXON               | object   | Ratio                                                                     | Formula <br> NN/39<br> *Differing number of N                                                                                                            | Exon* number<br>* Type of amino acid                                                                                                                                                                                 | Yes   |\n",
        "| INTRON             | object   | Ratio                                                                     | Formula <br> NN/38<br> *Differing number of N                                                                                                            | Intron* number<br>* Segment of DNA or RNA that<br>  interrupts sequence of genes                                                                                                                                     | No    |\n",
        "| cDNA_position      | object   | Interval                                                                  | Numeric Values                                                                                                                                           | Relative position of base pair in the<br> cDNA* sequence<br>* DNA from a single-strand RNA                                                                                                                           | Yes   |\n",
        "| CDS_position       | object   | Interval                                                                  | Numeric Values                                                                                                                                           | Relative position of base pair in the<br> coding sequence                                                                                                                                                            | No    |\n",
        "| Protein_position   | object   | Interval                                                                  | Numeric Values                                                                                                                                           | Relative position of amino acid in <br>protein                                                                                                                                                                       | No    |\n",
        "| Amino_acids        | object   | Nominal                                                                   | Formula<br> L<br> *Representing a protein                                                                                                                | Only given if the variant affects the<br> protein-coding sequence                                                                                                                                                    | No    |\n",
        "| Codons             | object   | Nominal                                                                   | strand of a, c, t, g                                                                                                                                     | Alternative codons* with the variant <br>affects the protein-coding sequence<br>* Sequence of 3 DNA/RNA that <br>  represents an amino acid or<br>  stop signal                                                      | No    |\n",
        "| DISTANCE           | float 64 | Interval                                                                  | Between 1 and 4759                                                                                                                                       | Shortest distance from variant to <br> transcript                                                                                                                                                                    | No    |\n",
        "| STRAND             | float 64 | Nominal                                                                   | 1 - forward<br>-1 - reverse                                                                                                                              | Defined as forward or reverse                                                                                                                                                                                        | No    |\n",
        "| BAM_EDIT           | object   | Nominal                                                                   | OK<br>Failed<br>null                                                                                                                                     | Indicates success or failure of edit<br> using BAM file                                                                                                                                                              | No    |\n",
        "| SIFT               | object   | Ordinal                                                                   | tolerated<br>deleterious<br>deleterious_low_confidence<br>tolerated_low_confidence<br>null                                                               | SIFT prediction* and/or score, with<br> both given as prediction<br>* Does an amino acid substitution<br>  affect the protein of the sequence                                                                        | Yes   |\n",
        "| PolyPhen           | object   | Ordinal                                                                   | benign<br>probably_damaging<br>possibly_damaging<br>null                                                                                                 | PolyPhen* prediction and/or score<br>* Polymorphism Phenotyping, or<br>  amino acid substitution affect                                                                                                              | Yes   |\n",
        "| MOTIF_NAME         | object   | Nominal                                                                   | null<br>Egr1:MA0341.1<br>FOXA1:MA0546.1                                                                                                                  | Source and identifier of a<br> transcription factor binding<br> profile aligned at this position                                                                                                                     | No    |\n",
        "| MOTIF_POS          | float 64 | Interval                                                                  | null<br>1                                                                                                                                                | Relative position of the variation<br> in the aligned TFBP*<br>* Transferrin-binding Protein, or<br>  iron-binding blood plasma                                                                                      | No    |\n",
        "| HIGH_INF_POS       | object   | Nominal                                                                   | null<br>N                                                                                                                                                | Flag indicating if the variant<br> falls in a high information<br> position of a transcription<br> factor binding profile                                                                                            | No    |\n",
        "| MOTIF_SCORE_CHANGE | float 64 | Interval                                                                  | null<br>-0.063<br>-0.097                                                                                                                                 | Difference in motif score* of the<br> reference and variant sequences<br> for the TFBP<br>* Genomic sequences that specifically<br>  bind to transcription factors                                                   | No    |\n",
        "| LoFtool            | float 64 | Ratio                                                                     | Between 0 and 1                                                                                                                                          | Loss of Function tolerance score<br> for the loss of function variants                                                                                                                                               | No    |\n",
        "| CADD_PHRED         | float 64 | Interval                                                                  | Between 0 and 99                                                                                                                                         | Phred-scaled CADD score*<br>* Rank of variant relative to <br>  substitution of human reference<br>  genome                                                                                                          | Yes   |\n",
        "| CADD_RAW           | float 64 | Interval                                                                  | Between -5.48 and 46.6                                                                                                                                   | Score of the deleteriousness*<br> of variants<br>* A genetic alteration that increases<br>  how susceptibility to a disease                                                                                          | No    |\n",
        "| BLOSUM62           | float 64 | Ordinal                                                                   | Between -3 and 3                                                                                                                                         | Scoring matrix for protein strings*<br>* how much does two sequences match                                                                                                                                           | No    |\n",
        "\n",
        "\n",
        "\n",
        "In summary,  we kept origin (the reference as to where the variant is located), impact (how much the variant could impact the person), ref (the allele that the variant changes), alt (the allele that it changed to), AF_EXAC and AF_TGP (frequencies of these variants), CADD_PHRED (a rank of substitution), EXON (type of amino acid), class (whether there's a conflict or not), sift (how much does this affect the genome), PolyPhen (the substitution affect), and cDNA_position (the position of the base pair). We did not end up creating any specific variables, as this dataset had all the necessary information within already existing variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jTpdBg2Mf3sC",
        "colab": {}
      },
      "source": [
        "# preprocess variables\n",
        "# dimensionality reduction\n",
        "# scaling\n",
        "# remove vars\n",
        "# create vars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TxLy-kKc8uM",
        "colab_type": "code",
        "outputId": "032816d3-fd46-410f-ed77-611edac38137",
        "colab": {}
      },
      "source": [
        "# Remove attributes that just arent useful for us\n",
        "# Removing features that aren't useful for our purposes (Columns that has less than 50% of data are deleted)\n",
        "for feat in ['DISTANCE', 'SSR', 'CLNDNINCL', 'CLNSIGINCL', 'CLNDISDBINCL', 'MOTIF_NAME', 'MOTIF_POS', 'HIGH_INF_POS', 'MOTIF_SCORE_CHANGE',\n",
        "            'BAM_EDIT', 'CLNVI', 'BLOSUM62', 'INTRON', 'Feature_type', 'BIOTYPE', 'Feature']:\n",
        "  if feat in original_data:\n",
        "    del original_data[feat]\n",
        "original_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>REF</th>\n",
              "      <th>ALT</th>\n",
              "      <th>AF_EXAC</th>\n",
              "      <th>AF_TGP</th>\n",
              "      <th>ORIGIN</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>IMPACT</th>\n",
              "      <th>EXON</th>\n",
              "      <th>SIFT</th>\n",
              "      <th>PolyPhen</th>\n",
              "      <th>CADD_PHRED</th>\n",
              "      <th>CADD_RAW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>0.00289</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>363/363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.170</td>\n",
              "      <td>1.091042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00063</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>LOW</td>\n",
              "      <td>363/363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.437</td>\n",
              "      <td>-0.142156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>363/363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.000</td>\n",
              "      <td>3.385304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GT</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>363/363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63.000</td>\n",
              "      <td>25.726748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>363/363</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.400</td>\n",
              "      <td>2.630719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62907</th>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.400</td>\n",
              "      <td>4.556305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62908</th>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.016</td>\n",
              "      <td>0.043467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62909</th>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.860</td>\n",
              "      <td>0.027997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62910</th>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.081</td>\n",
              "      <td>-0.055831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62911</th>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.734</td>\n",
              "      <td>0.844303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62912 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      REF ALT  AF_EXAC  AF_TGP  ORIGIN  CLASS    IMPACT     EXON SIFT  \\\n",
              "0       G   T  0.00289  0.0010     1.0      0  MODIFIER  363/363  NaN   \n",
              "1       A   G  0.00063  0.0004     1.0      1       LOW  363/363  NaN   \n",
              "2       C   A  0.00004  0.0000     1.0      0  MODERATE  363/363  NaN   \n",
              "3      GT   G  0.00001  0.0000     1.0      0      HIGH  363/363  NaN   \n",
              "4       A   C  0.00000  0.0000     1.0      1  MODERATE  363/363  NaN   \n",
              "...    ..  ..      ...     ...     ...    ...       ...      ...  ...   \n",
              "62907   G   A  0.00000  0.0000     1.0      0  MODIFIER      NaN  NaN   \n",
              "62908   T   C  0.00000  0.0000     1.0      1  MODIFIER      NaN  NaN   \n",
              "62909   T   C  0.00000  0.0000     1.0      1  MODIFIER      NaN  NaN   \n",
              "62910   T   C  0.00000  0.0000     1.0      1  MODIFIER      NaN  NaN   \n",
              "62911   A   G  0.00000  0.0000     1.0      1  MODIFIER      NaN  NaN   \n",
              "\n",
              "      PolyPhen  CADD_PHRED   CADD_RAW  \n",
              "0          NaN      11.170   1.091042  \n",
              "1          NaN       1.437  -0.142156  \n",
              "2          NaN      23.000   3.385304  \n",
              "3          NaN      63.000  25.726748  \n",
              "4          NaN      20.400   2.630719  \n",
              "...        ...         ...        ...  \n",
              "62907      NaN      24.400   4.556305  \n",
              "62908      NaN       3.016   0.043467  \n",
              "62909      NaN       2.860   0.027997  \n",
              "62910      NaN       2.081  -0.055831  \n",
              "62911      NaN       9.734   0.844303  \n",
              "\n",
              "[62912 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KxXhMsDc8uQ",
        "colab_type": "code",
        "outputId": "111058ed-290d-44c8-e9c9-605ac8aa67a4",
        "colab": {}
      },
      "source": [
        "categorical = ['IMPACT', 'SIFT', 'PolyPhen']\n",
        "len(categorical)\n",
        "\n",
        "unique_cat_values = []\n",
        "total_non_nans = []\n",
        "# make df for # unique values in the categorical features\n",
        "for feat in categorical:\n",
        "  unique_cat_values.append(original_data[feat].nunique())\n",
        "  total_non_nans.append(original_data[feat].count())\n",
        "unique_cat_values = pd.DataFrame({'Feature': categorical, 'Num_unique': unique_cat_values})\n",
        "total_non_nans = pd.DataFrame({'Feature': categorical, 'Non_Nan_Count': total_non_nans})\n",
        "unique_cat_values\n",
        "total_non_nans"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Non_Nan_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IMPACT</td>\n",
              "      <td>62912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SIFT</td>\n",
              "      <td>24772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PolyPhen</td>\n",
              "      <td>24732</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Feature  Non_Nan_Count\n",
              "0    IMPACT          62912\n",
              "1      SIFT          24772\n",
              "2  PolyPhen          24732"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyN4seKac8uT",
        "colab_type": "text"
      },
      "source": [
        "## Subset of the data\n",
        "\n",
        "For the purpose of this lab, we only use records that have PolyPhen value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vflF-Twyc8uT",
        "colab_type": "code",
        "outputId": "9db93146-432e-4172-f1a2-96192b3e4bdd",
        "colab": {}
      },
      "source": [
        "# We need to convert EXON to a ratio.  Right now the entries are like 1/10 instead\n",
        "# of .1 so we need to process that.\n",
        "subset_data_list = ['ORIGIN', 'IMPACT', 'REF', 'ALT', 'AF_EXAC', 'AF_TGP',\n",
        "                    'CADD_PHRED', 'EXON', 'CLASS', 'SIFT', 'PolyPhen']\n",
        "\n",
        "subset_data = original_data[subset_data_list]\n",
        "print(subset_data.info())\n",
        "subset_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62912 entries, 0 to 62911\n",
            "Data columns (total 11 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   ORIGIN      56789 non-null  float64\n",
            " 1   IMPACT      62912 non-null  object \n",
            " 2   REF         62912 non-null  object \n",
            " 3   ALT         62912 non-null  object \n",
            " 4   AF_EXAC     62912 non-null  float64\n",
            " 5   AF_TGP      62912 non-null  float64\n",
            " 6   CADD_PHRED  62554 non-null  float64\n",
            " 7   EXON        54028 non-null  object \n",
            " 8   CLASS       62912 non-null  int64  \n",
            " 9   SIFT        24772 non-null  object \n",
            " 10  PolyPhen    24732 non-null  object \n",
            "dtypes: float64(4), int64(1), object(6)\n",
            "memory usage: 5.3+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORIGIN</th>\n",
              "      <th>IMPACT</th>\n",
              "      <th>REF</th>\n",
              "      <th>ALT</th>\n",
              "      <th>AF_EXAC</th>\n",
              "      <th>AF_TGP</th>\n",
              "      <th>CADD_PHRED</th>\n",
              "      <th>EXON</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SIFT</th>\n",
              "      <th>PolyPhen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>G</td>\n",
              "      <td>T</td>\n",
              "      <td>0.00289</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>11.170</td>\n",
              "      <td>363/363</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>LOW</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00063</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>1.437</td>\n",
              "      <td>363/363</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>C</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>363/363</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>GT</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>63.000</td>\n",
              "      <td>363/363</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>A</td>\n",
              "      <td>C</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>20.400</td>\n",
              "      <td>363/363</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62907</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>24.400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62908</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3.016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62909</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.860</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62910</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>T</td>\n",
              "      <td>C</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.081</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62911</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODIFIER</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>9.734</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62912 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ORIGIN    IMPACT REF ALT  AF_EXAC  AF_TGP  CADD_PHRED     EXON  CLASS  \\\n",
              "0         1.0  MODIFIER   G   T  0.00289  0.0010      11.170  363/363      0   \n",
              "1         1.0       LOW   A   G  0.00063  0.0004       1.437  363/363      1   \n",
              "2         1.0  MODERATE   C   A  0.00004  0.0000      23.000  363/363      0   \n",
              "3         1.0      HIGH  GT   G  0.00001  0.0000      63.000  363/363      0   \n",
              "4         1.0  MODERATE   A   C  0.00000  0.0000      20.400  363/363      1   \n",
              "...       ...       ...  ..  ..      ...     ...         ...      ...    ...   \n",
              "62907     1.0  MODIFIER   G   A  0.00000  0.0000      24.400      NaN      0   \n",
              "62908     1.0  MODIFIER   T   C  0.00000  0.0000       3.016      NaN      1   \n",
              "62909     1.0  MODIFIER   T   C  0.00000  0.0000       2.860      NaN      1   \n",
              "62910     1.0  MODIFIER   T   C  0.00000  0.0000       2.081      NaN      1   \n",
              "62911     1.0  MODIFIER   A   G  0.00000  0.0000       9.734      NaN      1   \n",
              "\n",
              "      SIFT PolyPhen  \n",
              "0      NaN      NaN  \n",
              "1      NaN      NaN  \n",
              "2      NaN      NaN  \n",
              "3      NaN      NaN  \n",
              "4      NaN      NaN  \n",
              "...    ...      ...  \n",
              "62907  NaN      NaN  \n",
              "62908  NaN      NaN  \n",
              "62909  NaN      NaN  \n",
              "62910  NaN      NaN  \n",
              "62911  NaN      NaN  \n",
              "\n",
              "[62912 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfE5cSb6c8uY",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning Subset Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZGCyD1Xc8uZ",
        "colab_type": "text"
      },
      "source": [
        "Now we need to fix the EXON column to hold numeric ratio values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDghuvcAc8ua",
        "colab_type": "code",
        "outputId": "d2e63bc7-79d8-48d0-b0ca-d38f45caa427",
        "colab": {}
      },
      "source": [
        "# Fix EXON\n",
        "# subset_cc_data.EXON.apply(lambda x: np.nan if x.startswith('XXX') else x)\n",
        "def make_ratio(x):\n",
        "  fin = np.nan\n",
        "  try:\n",
        "    vals = x.split('/')\n",
        "    fin = float(vals[0]) / float(vals[-1])\n",
        "  except:\n",
        "    return fin \n",
        "  return fin\n",
        "subset_data.EXON = subset_data.EXON.apply(lambda x: make_ratio(x))\n",
        "# convert EXON to float datatype \n",
        "subset_data.EXON = subset_data.EXON.astype(float)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Skyler\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td6qXRVAc8uf",
        "colab_type": "code",
        "outputId": "6234616a-f53d-4bd6-e688-6de73ce35704",
        "colab": {}
      },
      "source": [
        "subset_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62912 entries, 0 to 62911\n",
            "Data columns (total 11 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   ORIGIN      56789 non-null  float64\n",
            " 1   IMPACT      62912 non-null  object \n",
            " 2   REF         62912 non-null  object \n",
            " 3   ALT         62912 non-null  object \n",
            " 4   AF_EXAC     62912 non-null  float64\n",
            " 5   AF_TGP      62912 non-null  float64\n",
            " 6   CADD_PHRED  62554 non-null  float64\n",
            " 7   EXON        23004 non-null  float64\n",
            " 8   CLASS       62912 non-null  int64  \n",
            " 9   SIFT        24772 non-null  object \n",
            " 10  PolyPhen    24732 non-null  object \n",
            "dtypes: float64(5), int64(1), object(5)\n",
            "memory usage: 5.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HM7vP1Ec8ui",
        "colab_type": "text"
      },
      "source": [
        "### Imputation\n",
        "\n",
        "We decided to use the KNN algorithm to impute our dataset. We chose KNN for the following reasons:\n",
        "\n",
        "KNN can impute all types of data (ordinal, categorical, etc.) if the distance metric is defined for each type of data. Although our categorical data is not missing any values, if we added to this dataset or if the dataset was expanded and had missing data once expanded, we could use our same imputation implementation as opposed to changing. Although sklearn does not seem to support this yet, there are other libraries that are able to do this.\n",
        "\n",
        "KNN is non-parametric which means that it does not make assumptions about the underlying data distributions. This is important because some of our data may not conform to any distribution.\n",
        "\n",
        "Already implemented by sklearn :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEcGIB6hc8uj",
        "colab_type": "code",
        "outputId": "ca4ac9e5-7d5b-4ffd-b388-fb5b27b2e083",
        "colab": {}
      },
      "source": [
        "print(subset_data.columns)\n",
        "columns = list(original_data.columns)\n",
        "# columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['ORIGIN', 'IMPACT', 'REF', 'ALT', 'AF_EXAC', 'AF_TGP', 'CADD_PHRED',\n",
            "       'EXON', 'CLASS', 'SIFT', 'PolyPhen'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4OmaylRc8un",
        "colab_type": "code",
        "outputId": "e61ea56d-640c-49ab-869d-1ef5a1c5fed6",
        "colab": {}
      },
      "source": [
        "numeric_cols = ['ORIGIN', 'AF_EXAC', 'AF_TGP', 'CADD_PHRED', 'EXON', 'CLASS']\n",
        "len(numeric_cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyS8WbCJc8up",
        "colab_type": "code",
        "outputId": "7b22eda5-486b-4f11-8a4c-20114da9d3c5",
        "colab": {}
      },
      "source": [
        "# courtesy of https://github.com/eclarson/MachineLearningNotebooks/blob/master/03.%20DataVisualization.ipynb :-)\n",
        "# changing it to work with our data\n",
        "# only doing this for some of the numeric features that we have\n",
        "# can't use this version of knn on non numeric values \n",
        "# https://towardsdatascience.com/the-use-of-knn-for-missing-values-cf33d935c637\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "import copy\n",
        "\n",
        "subset_numeric_cols = ['ORIGIN', 'CADD_PHRED', 'EXON'] # numeric cols that are acutally missing data\n",
        "knn_obj = KNNImputer(n_neighbors=7) # making smaller for memory reasons\n",
        "\n",
        "temp = subset_data[subset_numeric_cols].to_numpy()\n",
        "\n",
        "knn_obj.fit(temp)\n",
        "temp_imputed = knn_obj.transform(temp)\n",
        "\n",
        "imputed_subset_data = copy.deepcopy(subset_data)\n",
        "imputed_subset_data[subset_numeric_cols] = temp_imputed\n",
        "imputed_subset_data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62912 entries, 0 to 62911\n",
            "Data columns (total 11 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   ORIGIN      62912 non-null  float64\n",
            " 1   IMPACT      62912 non-null  object \n",
            " 2   REF         62912 non-null  object \n",
            " 3   ALT         62912 non-null  object \n",
            " 4   AF_EXAC     62912 non-null  float64\n",
            " 5   AF_TGP      62912 non-null  float64\n",
            " 6   CADD_PHRED  62912 non-null  float64\n",
            " 7   EXON        62912 non-null  float64\n",
            " 8   CLASS       62912 non-null  int64  \n",
            " 9   SIFT        24772 non-null  object \n",
            " 10  PolyPhen    24732 non-null  object \n",
            "dtypes: float64(5), int64(1), object(5)\n",
            "memory usage: 5.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1liY-n1c8uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicate_imputed_subset_data = copy.deepcopy(imputed_subset_data)\n",
        "duplicate_imputed_subset_data\n",
        "subset_data = copy.deepcopy(imputed_subset_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulIeUqOec8uy",
        "colab_type": "code",
        "outputId": "26df6007-ea4a-4721-857b-8bbfb314f91b",
        "colab": {}
      },
      "source": [
        "# Subset data now has only rows with PolyPhen values \n",
        "subset_data.drop(subset_data[subset_data['PolyPhen'].isnull() != False].index, inplace=True)\n",
        "subset_data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORIGIN</th>\n",
              "      <th>IMPACT</th>\n",
              "      <th>REF</th>\n",
              "      <th>ALT</th>\n",
              "      <th>AF_EXAC</th>\n",
              "      <th>AF_TGP</th>\n",
              "      <th>CADD_PHRED</th>\n",
              "      <th>EXON</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SIFT</th>\n",
              "      <th>PolyPhen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2182</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00153</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>31.000</td>\n",
              "      <td>0.988889</td>\n",
              "      <td>1</td>\n",
              "      <td>deleterious</td>\n",
              "      <td>probably_damaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2202</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.05423</td>\n",
              "      <td>0.0739</td>\n",
              "      <td>10.180</td>\n",
              "      <td>0.977778</td>\n",
              "      <td>0</td>\n",
              "      <td>tolerated</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.4591</td>\n",
              "      <td>20.500</td>\n",
              "      <td>0.911111</td>\n",
              "      <td>0</td>\n",
              "      <td>tolerated</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2250</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00040</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>21.700</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious</td>\n",
              "      <td>possibly_damaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>13.670</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54003</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>0.00169</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>3.515</td>\n",
              "      <td>0.762406</td>\n",
              "      <td>1</td>\n",
              "      <td>tolerated</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54009</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>0.00386</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>9.291</td>\n",
              "      <td>0.868482</td>\n",
              "      <td>0</td>\n",
              "      <td>tolerated_low_confidence</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54024</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>0.860505</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious_low_confidence</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54025</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>23.200</td>\n",
              "      <td>0.773079</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54026</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>23.700</td>\n",
              "      <td>0.756745</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious_low_confidence</td>\n",
              "      <td>benign</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24732 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ORIGIN    IMPACT REF ALT  AF_EXAC  AF_TGP  CADD_PHRED      EXON  CLASS  \\\n",
              "2182      1.0  MODERATE   T   G  0.00153  0.0018      31.000  0.988889      1   \n",
              "2202      1.0  MODERATE   A   G  0.05423  0.0739      10.180  0.977778      0   \n",
              "2247      1.0  MODERATE   G   A  0.00000  0.4591      20.500  0.911111      0   \n",
              "2250      1.0  MODERATE   A   G  0.00040  0.0012      21.700  0.900000      0   \n",
              "2261      1.0  MODERATE   A   G  0.00003  0.0002      13.670  0.888889      0   \n",
              "...       ...       ...  ..  ..      ...     ...         ...       ...    ...   \n",
              "54003     1.0  MODERATE   C   T  0.00169  0.0008       3.515  0.762406      1   \n",
              "54009     1.0  MODERATE   C   T  0.00386  0.0005       9.291  0.868482      0   \n",
              "54024     1.0      HIGH   G   A  0.00000  0.0000      23.000  0.860505      0   \n",
              "54025     1.0      HIGH   T   G  0.00000  0.0000      23.200  0.773079      0   \n",
              "54026     1.0      HIGH   T   A  0.00000  0.0000      23.700  0.756745      0   \n",
              "\n",
              "                             SIFT           PolyPhen  \n",
              "2182                  deleterious  probably_damaging  \n",
              "2202                    tolerated             benign  \n",
              "2247                    tolerated             benign  \n",
              "2250                  deleterious  possibly_damaging  \n",
              "2261                  deleterious             benign  \n",
              "...                           ...                ...  \n",
              "54003                   tolerated             benign  \n",
              "54009    tolerated_low_confidence             benign  \n",
              "54024  deleterious_low_confidence             benign  \n",
              "54025                 deleterious             benign  \n",
              "54026  deleterious_low_confidence             benign  \n",
              "\n",
              "[24732 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh1DJs40c8u0",
        "colab_type": "code",
        "outputId": "12eee804-f3d2-4a4f-fc01-5ed8bfab89bc",
        "colab": {}
      },
      "source": [
        "#Convert Polyphen to categorical\n",
        "subset_data['PolyPhen category'] = pd.factorize(subset_data['PolyPhen'])[0] + 1\n",
        "subset_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORIGIN</th>\n",
              "      <th>IMPACT</th>\n",
              "      <th>REF</th>\n",
              "      <th>ALT</th>\n",
              "      <th>AF_EXAC</th>\n",
              "      <th>AF_TGP</th>\n",
              "      <th>CADD_PHRED</th>\n",
              "      <th>EXON</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SIFT</th>\n",
              "      <th>PolyPhen</th>\n",
              "      <th>PolyPhen category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2182</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00153</td>\n",
              "      <td>0.0018</td>\n",
              "      <td>31.000</td>\n",
              "      <td>0.988889</td>\n",
              "      <td>1</td>\n",
              "      <td>deleterious</td>\n",
              "      <td>probably_damaging</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2202</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.05423</td>\n",
              "      <td>0.0739</td>\n",
              "      <td>10.180</td>\n",
              "      <td>0.977778</td>\n",
              "      <td>0</td>\n",
              "      <td>tolerated</td>\n",
              "      <td>benign</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.4591</td>\n",
              "      <td>20.500</td>\n",
              "      <td>0.911111</td>\n",
              "      <td>0</td>\n",
              "      <td>tolerated</td>\n",
              "      <td>benign</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2250</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00040</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>21.700</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious</td>\n",
              "      <td>possibly_damaging</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>A</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>13.670</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious</td>\n",
              "      <td>benign</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54003</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>0.00169</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>3.515</td>\n",
              "      <td>0.762406</td>\n",
              "      <td>1</td>\n",
              "      <td>tolerated</td>\n",
              "      <td>benign</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54009</th>\n",
              "      <td>1.0</td>\n",
              "      <td>MODERATE</td>\n",
              "      <td>C</td>\n",
              "      <td>T</td>\n",
              "      <td>0.00386</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>9.291</td>\n",
              "      <td>0.868482</td>\n",
              "      <td>0</td>\n",
              "      <td>tolerated_low_confidence</td>\n",
              "      <td>benign</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54024</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>G</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>0.860505</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious_low_confidence</td>\n",
              "      <td>benign</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54025</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>T</td>\n",
              "      <td>G</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>23.200</td>\n",
              "      <td>0.773079</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious</td>\n",
              "      <td>benign</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54026</th>\n",
              "      <td>1.0</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>T</td>\n",
              "      <td>A</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>23.700</td>\n",
              "      <td>0.756745</td>\n",
              "      <td>0</td>\n",
              "      <td>deleterious_low_confidence</td>\n",
              "      <td>benign</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24732 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ORIGIN    IMPACT REF ALT  AF_EXAC  AF_TGP  CADD_PHRED      EXON  CLASS  \\\n",
              "2182      1.0  MODERATE   T   G  0.00153  0.0018      31.000  0.988889      1   \n",
              "2202      1.0  MODERATE   A   G  0.05423  0.0739      10.180  0.977778      0   \n",
              "2247      1.0  MODERATE   G   A  0.00000  0.4591      20.500  0.911111      0   \n",
              "2250      1.0  MODERATE   A   G  0.00040  0.0012      21.700  0.900000      0   \n",
              "2261      1.0  MODERATE   A   G  0.00003  0.0002      13.670  0.888889      0   \n",
              "...       ...       ...  ..  ..      ...     ...         ...       ...    ...   \n",
              "54003     1.0  MODERATE   C   T  0.00169  0.0008       3.515  0.762406      1   \n",
              "54009     1.0  MODERATE   C   T  0.00386  0.0005       9.291  0.868482      0   \n",
              "54024     1.0      HIGH   G   A  0.00000  0.0000      23.000  0.860505      0   \n",
              "54025     1.0      HIGH   T   G  0.00000  0.0000      23.200  0.773079      0   \n",
              "54026     1.0      HIGH   T   A  0.00000  0.0000      23.700  0.756745      0   \n",
              "\n",
              "                             SIFT           PolyPhen  PolyPhen category  \n",
              "2182                  deleterious  probably_damaging                  1  \n",
              "2202                    tolerated             benign                  2  \n",
              "2247                    tolerated             benign                  2  \n",
              "2250                  deleterious  possibly_damaging                  3  \n",
              "2261                  deleterious             benign                  2  \n",
              "...                           ...                ...                ...  \n",
              "54003                   tolerated             benign                  2  \n",
              "54009    tolerated_low_confidence             benign                  2  \n",
              "54024  deleterious_low_confidence             benign                  2  \n",
              "54025                 deleterious             benign                  2  \n",
              "54026  deleterious_low_confidence             benign                  2  \n",
              "\n",
              "[24732 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ8ojh_Hc8u2",
        "colab_type": "text"
      },
      "source": [
        "#### PolyPhen category:\n",
        "##### 1 - probably_damaging\n",
        "##### 2 - benign\n",
        "##### 3 - possibly damaging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wEjuZ2oafFQV"
      },
      "source": [
        "### ***5 points***\n",
        "Divide you data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNDrZWnUgBCz",
        "colab": {}
      },
      "source": [
        "# divide training / testing\n",
        "# cross-validation modules scikit learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(subset_data, subset_data['PolyPhen category'], test_size=0.20)\n",
        "X = subset_data\n",
        "y = subset_data['PolyPhen category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JqFLOmz1gBap"
      },
      "source": [
        "*Explain answer here*\n",
        "\n",
        "In this case, an 80/20 split makes sense for our data. This is because we want to train the data on the genetic variants that do not having conflicting information, with a cases of genetic variants that do have conflicting information. This is so that we can analyze if certain labs are over labeling benign or pathogenic, what labs agree what percent of the time, etc. This allows us to take the 20% of the data that we did not train with to really see if our algorithm does well. We have a large amount of data in this dataset, as well as less concern on the amount of time we need to be able to train our data. This means we can use more time to train the dataset. We also need to make sure our dataset can handle outliers, so we need to make sure we have a big enough test section to be able to classify things correctly. This leads us to believe we should use an 80/20 split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X-nOMA5vduRG"
      },
      "source": [
        "## Modeling [***50 points***]\n",
        "\n",
        "The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xV5RGFlNd2o4"
      },
      "source": [
        "### ***20 points***\n",
        "Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier: <br />\n",
        "<ul>\n",
        "<li>Ability to choose optimization technique when class is instantiated: either steepest descent, stochastic gradient descent, or Newton's method. </li>\n",
        "<li>Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l1etWLRPlM3G",
        "outputId": "b0cc02e9-f90e-4436-ce5f-ecfc4470e2c9",
        "colab": {}
      },
      "source": [
        "# logistic classifier using numpy and scipy\n",
        "# OO conventions identical to scikit\n",
        "# start with Larson code\n",
        "X_train.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 19785 entries, 26590 to 41275\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   ORIGIN             19785 non-null  float64\n",
            " 1   IMPACT             19785 non-null  object \n",
            " 2   REF                19785 non-null  object \n",
            " 3   ALT                19785 non-null  object \n",
            " 4   AF_EXAC            19785 non-null  float64\n",
            " 5   AF_TGP             19785 non-null  float64\n",
            " 6   CADD_PHRED         19785 non-null  float64\n",
            " 7   EXON               19785 non-null  float64\n",
            " 8   CLASS              19785 non-null  int64  \n",
            " 9   SIFT               19686 non-null  object \n",
            " 10  PolyPhen           19785 non-null  object \n",
            " 11  PolyPhen category  19785 non-null  int64  \n",
            "dtypes: float64(5), int64(2), object(5)\n",
            "memory usage: 2.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8zcittsc8vB",
        "colab_type": "code",
        "outputId": "edd9a43b-aa48-419b-934f-dc58c2a07f1e",
        "colab": {}
      },
      "source": [
        "\n",
        "# from last time, our logistic regression algorithm is given by (including everything we previously had):\n",
        "class BinaryLogisticRegression:\n",
        "    def __init__(self, eta, iterations=20, C=0.001):\n",
        "        self.eta = eta\n",
        "        self.iters = iterations\n",
        "        self.C = C\n",
        "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
        "        \n",
        "    def __str__(self):\n",
        "        if(hasattr(self,'w_')):\n",
        "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
        "        else:\n",
        "            return 'Untrained Binary Logistic Regression Object'\n",
        "        \n",
        "    # convenience, private:\n",
        "    @staticmethod\n",
        "    def _add_bias(X):\n",
        "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
        "    \n",
        "    @staticmethod\n",
        "    def _sigmoid(theta):\n",
        "        # increase stability, redefine sigmoid operation\n",
        "        return expit(theta) #1/(1+np.exp(-theta))\n",
        "    \n",
        "    # vectorized gradient calculation with regularization using L2 Norm\n",
        "    def _get_gradient(self,X,y):\n",
        "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
        "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
        "        \n",
        "        gradient = gradient.reshape(self.w_.shape)\n",
        "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
        "        \n",
        "        return gradient\n",
        "    \n",
        "    # public:\n",
        "    def predict_proba(self,X,add_bias=True):\n",
        "        # add bias term if requested\n",
        "        Xb = self._add_bias(X) if add_bias else X\n",
        "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
        "    \n",
        "    def predict(self,X):\n",
        "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        Xb = self._add_bias(X) # add bias term\n",
        "        num_samples, num_features = Xb.shape\n",
        "        \n",
        "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
        "        \n",
        "        # for as many as the max iterations\n",
        "        for _ in range(self.iters):\n",
        "            gradient = self._get_gradient(Xb,y)\n",
        "            self.w_ += gradient*self.eta # multiply by learning rate \n",
        "            # add bacause maximizing \n",
        "\n",
        "blr = BinaryLogisticRegression(eta=0.1,iterations=500,C=0.001)\n",
        "\n",
        "cat_lr = ['PolyPhen', 'SIFT', 'ALT', 'REF', 'IMPACT'] #non-numeric columns\n",
        "\n",
        "lr_data_X_train = copy.deepcopy(X_train)\n",
        "lr_data_X_test = copy.deepcopy(X_test)\n",
        "lr_data_Y_train = copy.deepcopy(Y_train)\n",
        "lr_data_Y_test = copy.deepcopy(Y_test)\n",
        "\n",
        "for feat in cat_lr:\n",
        "  if feat in lr_data_X_train:\n",
        "    del lr_data_X_train[feat]\n",
        "    del lr_data_X_test[feat]\n",
        "\n",
        "blr.fit(lr_data_X_train, lr_data_Y_train)\n",
        "print(blr)\n",
        "\n",
        "yhat = blr.predict(lr_data_X_test)\n",
        "print('Accuracy of: ',accuracy_score(lr_data_Y_test,yhat))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary Logistic Regression Object with coefficients:\n",
            "[[4.27257442e+01]\n",
            " [5.72585519e+01]\n",
            " [3.85349275e-01]\n",
            " [4.03120477e-01]\n",
            " [7.19477827e+02]\n",
            " [3.12903370e+01]\n",
            " [1.07447888e+01]\n",
            " [9.63892371e+01]]\n",
            "Accuracy of:  0.29896907216494845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iKc4uiZd1hj",
        "colab_type": "text"
      },
      "source": [
        "The above code is that for Binary Logistic Regression. The accuracy for this is 29%. This is performing normal logistic regression using sigmoids and gradients. This is our implementation of steepest descent. It did not function well, as evident by the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8hEasc6c8vE",
        "colab_type": "code",
        "outputId": "5520c78a-de76-4c1d-dc37-a97dc369dd71",
        "colab": {}
      },
      "source": [
        "# and we can update this to use a line search along the gradient like this:\n",
        "from scipy.optimize import minimize_scalar\n",
        "import copy\n",
        "class LineSearchLogisticRegression(BinaryLogisticRegression):\n",
        "    \n",
        "    # define custom line search for problem\n",
        "    \n",
        "    @staticmethod\n",
        "    def objective_function(eta,X,y,w,grad,C):\n",
        "        wnew = w - grad*eta\n",
        "        g = expit(X @ wnew)\n",
        "        return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(wnew**2)\n",
        "    \n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        Xb = self._add_bias(X) # add bias term\n",
        "        num_samples, num_features = Xb.shape\n",
        "        \n",
        "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
        "        \n",
        "        # for as many as the max iterations\n",
        "        for _ in range(self.iters):\n",
        "            gradient = -self._get_gradient(Xb,y)\n",
        "            # minimization inopposite direction\n",
        "            \n",
        "            # do line search in gradient direction, using scipy function\n",
        "            opts = {'maxiter':self.iters/50} # unclear exactly what this should be\n",
        "            res = minimize_scalar(self.objective_function, # objective function to optimize\n",
        "                                  bounds=(self.eta/1000,self.eta*10), #bounds to optimize\n",
        "                                  args=(Xb,y,self.w_,gradient,self.C), # additional argument for objective function\n",
        "                                  method='bounded', # bounded optimization for speed\n",
        "                                  options=opts) # set max iterations\n",
        "            \n",
        "            eta = res.x # get optimal learning rate\n",
        "            self.w_ -= gradient*eta # set new function values\n",
        "            # subtract to minimize\n",
        "                \n",
        "            \n",
        "\n",
        "lslr = LineSearchLogisticRegression(eta=0.01,iterations=40, C=0.001)\n",
        "\n",
        "lslr.fit(lr_data_X_train, lr_data_Y_train)\n",
        "\n",
        "yhat = lslr.predict(lr_data_X_test)\n",
        "print(lslr)\n",
        "print('Accuracy of: ',accuracy_score(lr_data_Y_test, yhat))     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary Logistic Regression Object with coefficients:\n",
            "[[1.68332371e+00]\n",
            " [2.36926996e+00]\n",
            " [1.59407004e-02]\n",
            " [1.66686746e-02]\n",
            " [2.96903167e+01]\n",
            " [1.29301281e+00]\n",
            " [4.43965126e-01]\n",
            " [3.96570016e+00]]\n",
            "Accuracy of:  0.29896907216494845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w2U-1IZc8vL",
        "colab_type": "code",
        "outputId": "196b8037-51c2-4501-9715-3b7cce26000b",
        "colab": {}
      },
      "source": [
        "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
        "    # stochastic gradient calculation \n",
        "    def _get_gradient(self,X,y):\n",
        "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
        "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
        "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
        "        \n",
        "        gradient = gradient.reshape(self.w_.shape)\n",
        "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
        "        \n",
        "        return gradient\n",
        "    \n",
        "    \n",
        "slr = StochasticLogisticRegression(0.05,500, C=0.001) # take a lot more steps!!\n",
        "    \n",
        "slr.fit(lr_data_X_train, lr_data_Y_train)\n",
        "\n",
        "yhat = slr.predict(lr_data_X_test)\n",
        "print(slr)\n",
        "print('Accuracy of: ',accuracy_score(lr_data_Y_test, yhat))        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "11368",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-23-11b275bb07a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mslr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStochasticLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# take a lot more steps!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mslr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_data_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_data_Y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_data_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-18-001e3a406b9d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# for as many as the max iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta\u001b[0m \u001b[1;31m# multiply by learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;31m# add bacause maximizing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-23-11b275bb07a2>\u001b[0m in \u001b[0;36m_get_gradient\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# grab random instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mydiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madd_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# get y difference (now scalar)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mydiff\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# make ydiff a column vector and multiply through\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4404\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4405\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4406\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 11368"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjGxHxjZeKyE",
        "colab_type": "text"
      },
      "source": [
        "Above is the code for Stochastic Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVDqJ4FSc8vN",
        "colab_type": "code",
        "outputId": "197ec5c5-0e11-4754-d6fe-63f57be1a710",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from numpy.linalg import pinv\n",
        "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
        "    # just overwrite gradient function\n",
        "    def _get_gradient(self,X,y):\n",
        "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
        "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
        "\n",
        "        ydiff = y-g # get y difference\n",
        "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
        "        gradient = gradient.reshape(self.w_.shape)\n",
        "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
        "        \n",
        "        return pinv(hessian) @ gradient\n",
        "       \n",
        "hlr = HessianBinaryLogisticRegression(eta=1.0,iterations=1,C=0.001) # note that we need only a few iterations here\n",
        "\n",
        "hlr.fit(lr_data_X_train, lr_data_Y_train)\n",
        "yhat = hlr.predict(lr_data_X_test)\n",
        "print(hlr)\n",
        "print('Accuracy of: ',accuracy_score(lr_data_Y_test,yhat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Binary Logistic Regression Object with coefficients:\n",
            "[[-2.00001463e+00]\n",
            " [-2.69502741e-08]\n",
            " [ 2.21632764e-04]\n",
            " [ 2.62575828e-04]\n",
            " [ 8.79088545e-08]\n",
            " [ 1.64016403e-05]\n",
            " [ 7.34742671e-06]\n",
            " [ 3.99999740e+00]]\n",
            "Accuracy of:  0.29896907216494845\n",
            "Wall time: 990 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOq3qe7XeT5a",
        "colab_type": "text"
      },
      "source": [
        "The above code is for Hessian Binary Logistic Regression. The accuracy for this is still 30%. This means that the added Hessian matrix did not add any more accuracy to our prediction, and thus did not help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWEBBBAgc8vT",
        "colab_type": "text"
      },
      "source": [
        "#### L2 regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5VAIYGqc8vU",
        "colab_type": "code",
        "outputId": "1203ffaa-a3fb-4e76-a6c9-27fe795ac0d1",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# for this, we won't perform our own BFGS implementation \n",
        "# (it takes a good deal of code and understanding of the algorithm)\n",
        "# luckily for us, scipy has its own BFGS implementation:\n",
        "from scipy.optimize import fmin_bfgs\n",
        "class BFGSBinaryLogisticRegressionL2(BinaryLogisticRegression):\n",
        "    \n",
        "    @staticmethod\n",
        "    def objective_function(w,X,y,C):\n",
        "        g = expit(X @ w)\n",
        "        return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(w**2) #-np.sum(y*np.log(g)+(1-y)*np.log(1-g))\n",
        "\n",
        "    @staticmethod\n",
        "    def objective_gradient(w,X,y,C):\n",
        "        g = expit(X @ w)\n",
        "        ydiff = y-g # get y difference\n",
        "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
        "        gradient = gradient.reshape(w.shape)\n",
        "        gradient[1:] += -2 * w[1:] * C\n",
        "        return -gradient\n",
        "    \n",
        "    # just overwrite fit function\n",
        "    def fit(self, X, y):\n",
        "        Xb = self._add_bias(X) # add bias term\n",
        "        num_samples, num_features = Xb.shape\n",
        "        \n",
        "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
        "                            np.zeros((num_features,1)), # starting point\n",
        "                            fprime=self.objective_gradient, # gradient function\n",
        "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
        "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
        "                            maxiter=self.iters, # stopping criteria iterations\n",
        "                            disp=False)\n",
        "        \n",
        "        self.w_ = self.w_.reshape((num_features,1))\n",
        "\n",
        "\n",
        "bfgslr2 = BFGSBinaryLogisticRegressionL2(_,2,C=0.001) # note that we need only a few iterations here\n",
        "bfgslr2.fit(lr_data_X_train, lr_data_Y_train)\n",
        "yhat = bfgslr2.predict(lr_data_X_test)\n",
        "print('BFGSBinaryLogisticRegression L2 Regularization')\n",
        "print(bfgslr2)\n",
        "print('Accuracy of: ',accuracy_score(lr_data_Y_test,yhat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BFGSBinaryLogisticRegression L2 Regularization\n",
            "Binary Logistic Regression Object with coefficients:\n",
            "[[5.40092980e-02]\n",
            " [7.98820690e-02]\n",
            " [4.85696515e-04]\n",
            " [5.05355789e-04]\n",
            " [9.97502383e-01]\n",
            " [4.15302410e-02]\n",
            " [1.42740660e-02]\n",
            " [1.17736336e-01]]\n",
            "Accuracy of:  0.29896907216494845\n",
            "Wall time: 140 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZOy065lepod",
        "colab_type": "text"
      },
      "source": [
        "The above code is for BFGS Binary Logistic Regression. Yet again, the prediction accuracy is still around 30%. This is starting to indicate that there could be something wrong with the prediction task, and it may not be possible. This was using L2, aka Ridge Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnjfQpt-c8vX",
        "colab_type": "text"
      },
      "source": [
        "#### L1 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reKehoVbc8vY",
        "colab_type": "code",
        "outputId": "c83e9f37-ee00-4bab-8e81-6438c45a6a7b",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# for this, we won't perform our own BFGS implementation \n",
        "# (it takes a good deal of code and understanding of the algorithm)\n",
        "# luckily for us, scipy has its own BFGS implementation:\n",
        "from scipy.optimize import fmin_bfgs\n",
        "class BFGSBinaryLogisticRegressionL1(BinaryLogisticRegression):\n",
        "    \n",
        "    @staticmethod\n",
        "    def objective_function(w,X,y,C):\n",
        "        g = expit(X @ w)\n",
        "        return -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(w) \n",
        "\n",
        "    @staticmethod\n",
        "    def objective_gradient(w,X,y,C):\n",
        "        g = expit(X @ w)\n",
        "        ydiff = y-g # get y difference\n",
        "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
        "        gradient = gradient.reshape(w.shape)\n",
        "        gradient[1:] += - w[1:] * C \n",
        "        return -gradient\n",
        "    \n",
        "    # just overwrite fit function\n",
        "    def fit(self, X, y):\n",
        "        Xb = self._add_bias(X) # add bias term\n",
        "        num_samples, num_features = Xb.shape\n",
        "        \n",
        "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
        "                            np.zeros((num_features,1)), # starting point\n",
        "                            fprime=self.objective_gradient, # gradient function\n",
        "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
        "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
        "                            maxiter=self.iters, # stopping criteria iterations\n",
        "                            disp=False)\n",
        "        \n",
        "        self.w_ = self.w_.reshape((num_features,1))\n",
        "            \n",
        "bfgslr1 = BFGSBinaryLogisticRegressionL1(_,2,C=0.001) # note that we need only a few iterations here\n",
        "\n",
        "bfgslr1.fit(lr_data_X_train, lr_data_Y_train)\n",
        "yhat = bfgslr1.predict(lr_data_X_test)\n",
        "print('BFGSBinaryLogisticRegression L1 Regularization')\n",
        "print(bfgslr1)\n",
        "print('Accuracy of: ',accuracy_score(lr_data_Y_test,yhat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BFGSBinaryLogisticRegression L1 Regularization\n",
            "Binary Logistic Regression Object with coefficients:\n",
            "[[5.40092980e-02]\n",
            " [7.98820690e-02]\n",
            " [4.85696515e-04]\n",
            " [5.05355789e-04]\n",
            " [9.97502383e-01]\n",
            " [4.15302410e-02]\n",
            " [1.42740660e-02]\n",
            " [1.17736336e-01]]\n",
            "Accuracy of:  0.29896907216494845\n",
            "Wall time: 150 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92FliiZOe27m",
        "colab_type": "text"
      },
      "source": [
        "The above code is for BFGS Binary Logistic Regression using Lasso Regression, aka L1. The percentage of accuracy is yet again around 29%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lbGa7-rc8va",
        "colab_type": "text"
      },
      "source": [
        "####  Both L1 & L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm49Cph0c8vb",
        "colab_type": "code",
        "outputId": "aad74b80-8bfa-49c7-8932-d7fe300904af",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# for this, we won't perform our own BFGS implementation \n",
        "# (it takes a good deal of code and understanding of the algorithm)\n",
        "# luckily for us, scipy has its own BFGS implementation:\n",
        "from scipy.optimize import fmin_bfgs\n",
        "class BFGSBinaryLogisticRegressionL1L2(BinaryLogisticRegression):\n",
        "    \n",
        "    @staticmethod\n",
        "    def objective_function(w,X,y,C):\n",
        "        g = expit(X @ w)\n",
        "        return ( -np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(w) ) + (-np.sum(np.log(g[y==1]))-np.sum(np.log(1-g[y==0])) + C*sum(w**2))\n",
        "\n",
        "    @staticmethod\n",
        "    def objective_gradient(w,X,y,C):\n",
        "        g = expit(X @ w)\n",
        "        ydiff = y-g # get y difference\n",
        "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
        "        gradient = gradient.reshape(w.shape)\n",
        "        gradient[1:] += - w[1:] * C - 2 * w[1:] * C\n",
        "        return -gradient\n",
        "    \n",
        "    # just overwrite fit function\n",
        "    def fit(self, X, y):\n",
        "        Xb = self._add_bias(X) # add bias term\n",
        "        num_samples, num_features = Xb.shape\n",
        "        \n",
        "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
        "                            np.zeros((num_features,1)), # starting point\n",
        "                            fprime=self.objective_gradient, # gradient function\n",
        "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
        "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
        "                            maxiter=self.iters, # stopping criteria iterations\n",
        "                            disp=False)\n",
        "        \n",
        "        self.w_ = self.w_.reshape((num_features,1))\n",
        "            \n",
        "bfgslr12 = BFGSBinaryLogisticRegressionL1L2(_,2,C=0.001) # note that we need only a few iterations here\n",
        "\n",
        "bfgslr12.fit(lr_data_X_train, lr_data_Y_train)\n",
        "yhat = bfgslr12.predict(lr_data_X_test)\n",
        "print('BFGSBinaryLogisticRegression L1 & L2 Regularization')\n",
        "print(bfgslr12)\n",
        "print('Accuracy of: ',accuracy_score(lr_data_Y_test,yhat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BFGSBinaryLogisticRegression L1 & L2 Regularization\n",
            "Binary Logistic Regression Object with coefficients:\n",
            "[[5.40092980e-02]\n",
            " [7.98820690e-02]\n",
            " [4.85696515e-04]\n",
            " [5.05355789e-04]\n",
            " [9.97502383e-01]\n",
            " [4.15302410e-02]\n",
            " [1.42740660e-02]\n",
            " [1.17736336e-01]]\n",
            "Accuracy of:  0.29896907216494845\n",
            "Wall time: 192 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8EdfGJbDlwDU"
      },
      "source": [
        "Using both L1 and L2, this is still an accuracy around 29%. This prediction task ended up being much harder and more complicated than it originally seemed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "99hlXc-AeVS3"
      },
      "source": [
        "### ***15 points***\n",
        "Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term \"C\" to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated. Is your method of selecting parameters justified? That is, do you think there is any \"data snooping\" involved with this method of selecting parameters?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UeE9wXvVl0oz",
        "colab": {}
      },
      "source": [
        "# get good generalization performance aka technique and C adjustment\n",
        "\n",
        "indexL1 = []\n",
        "accuracyL1 = []\n",
        "\n",
        "indexL2 = []\n",
        "accuracyL2 = []\n",
        "\n",
        "indexL1L2 = []\n",
        "accuracyL1L2 = []\n",
        "\n",
        "for i in range(0, 20):\n",
        "    C_step = 0.001+i*0.01\n",
        "    \n",
        "    # L1\n",
        "    bfgslr1 = BFGSBinaryLogisticRegressionL1(_,2,C=C_step) # note that we need only a few iterations here\n",
        "    bfgslr1.fit(lr_data_X_train, lr_data_Y_train)\n",
        "    yhat = bfgslr1.predict(lr_data_X_test)\n",
        "    indexL1.append(C_step)\n",
        "    accuracyL1.append(accuracy_score(lr_data_Y_test,yhat))\n",
        "    \n",
        "    # L2\n",
        "    bfgslr2 = BFGSBinaryLogisticRegressionL2(_,2,C=C_step) # note that we need only a few iterations here\n",
        "    bfgslr2.fit(lr_data_X_train, lr_data_Y_train)\n",
        "    yhat = bfgslr2.predict(lr_data_X_test)\n",
        "    indexL2.append(C_step)\n",
        "    accuracyL2.append(accuracy_score(lr_data_Y_test,yhat))\n",
        "    \n",
        "    # L1L2\n",
        "    bfgslr12 = BFGSBinaryLogisticRegressionL1L2(_,2,C=C_step) # note that we need only a few iterations here\n",
        "    bfgslr12.fit(lr_data_X_train, lr_data_Y_train)\n",
        "    yhat = bfgslr12.predict(lr_data_X_test)\n",
        "    indexL1L2.append(C_step)\n",
        "    accuracyL1L2.append(accuracy_score(lr_data_Y_test,yhat))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIxC20edc8vi",
        "colab_type": "text"
      },
      "source": [
        "##### Above, we're using L1, L2, L1&L2 and adjusting C to see different results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tUNutiFc8vj",
        "colab_type": "code",
        "outputId": "f03b913c-a71f-4ddb-8fdc-b813750dbe4c",
        "colab": {}
      },
      "source": [
        "# visualize performance classifier vs params investigated\n",
        "plt.plot(indexL1, accuracyL1, color='g', label=\"L1\")\n",
        "plt.plot(indexL2, accuracyL2, color='orange', label=\"L2\")\n",
        "plt.plot(indexL1L2, accuracyL1L2, color='blue', label=\"L1&L2\")\n",
        "\n",
        "plt.xlabel('C adjustment')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Visualization of performance classifier vs params investigated')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEWCAYAAADLkvgyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3de5wcVZn/8c+XhBDulxAQmEBCiEDgF0IYI7gYQWCFLBpYZbmLwgoBURFEWNd1QWSNLKLsiiAEBERBrpJVJEgUUAHNBEIkcgsQYLiEEK7hIgk8vz/OGVPp9Mz0JNNdHeb7fr3mNV2Xc+qp01X1dJ2urlJEYGZmVqZVyg7AzMzMycjMzErnZGRmZqVzMjIzs9I5GZmZWemcjMzMrHQrZTKSNFvSbnVeRkjaKr++QNJ/1GEZv5Z0RG/XW8NyvyXpBUnPNWh5x0qaJ2mhpEGNWGazkjRX0p51qvvDkh4qDG8t6V5Jr0n6Yr22Y4O8bW9ZdhwdJB0q6Zay4wCQdJqkK7qdr9l+ZyRpKvCniPhGxfgJwI+AlohY3IA4AhgREXN6qb7TgK0i4rDeqG8F4hgCPAxsERHPN2B5qwKvAjtHxH31Xl6zkzQX+NeIuLUBy7oYeDUivlzvZVl5JA0FHgdWrcexcUW32VqPfc14ZnQpcLgkVYw/HPhpIxLRe9wWwIIGJaL+wMbAQGD2cpSXpGbcRlcWW7Ac7V4pv49Nb2WJ0zoREU31B6wOvAKMK4xbH3gL2CEPzwX2zK/HAm2kT9/zgHPy+N2A9oq6K8vdBbwMPAv8ABhQmDdI2RxSgvxWfv1/wMLC37vAZ/K0c4GnciwzgA/n8XsDbwOLcpn78vjbSJ84IH0w+DrwBPA8cDmwbp42NMdzBPAk8ALw71204bq5/Pxc39dz/XsCb+aYFwKXVim7G9AOfC0vZy5waGH6asDZOY55wAXA6hVlTwGeA64EXs+xLwR+m+f7EDA9v8/TgQ8V6r8NOBP4Y451q1z+OOAR4DXgDGB4fv9eBa7ueO9I28ov87q/lF+3VNR/Rq7/NeAWYMPC9F2BO0nbxVOF97bT9e7kPfgc8EBexl+BMT3ZBgEB38vbwivALGD7PG18rvM14GngK5XbPPBb4B3SfrMQeD+F7TjPsy8wMy//TmBUxb5ySl7u34D+Fet3AXB2xbgbgRPz61NybK8BDwF7dNJOl+a6fpPnvZ101t4xveo+laedBlwLXJGn/2tXbVrYr2vdljYkbT8vAy8CvwdW6WQ9Ko8X5wG/ysv4EzC8xnbbFLiOtP0+DnyxMF9nx7onWbKPLQR2AT4D/KFQ9h/z+/AK8MPczh3HnuF5e1lA2ud/CqyXp/2EdLx4M9f91Tx+Z5bsJ/cBuxWWNSzX/1p+X38AXNHtsb+eiWV5/4CLgMmF4WOAmRU7SscOfRdweH69Fqk7CLpPRjvlBu1POtg/AJzQxcb1rSpx7g08AwzJw4cBg3KdJ5EOyAMLO84VFeVvK2wQRwJzgC3zelwP/CRPG5rjuYiUrHcgHSC27aT9Lidt4Gvnsg8DR3XWLhVldwMWA+eQDsAfISWUrfP07wNTgA1y/f8HfLui7Hdy2dULsffP82xAShKH53Y6OA8PKrTJk8B2efqqufwUYJ08/m/AtNxW65IOzEfk8oOATwJr5PiuAX5R0eaPkg7Oq+fhSXna5qQd6OC83EHA6O7Wu0obHkA6EH+AlFS2Ih9gqXEbBD5GOviul+vYFtgkT3uWJR901mdJolvqvaWwfVVux8AYUqL7INCP9EFnLrBaIc6ZwBCqJF1gHClJqBDHm6SD6dZ52qaF7Xd4J211aW7zcaRt5lyWPoh2t08tAvYjfdhavas2LezXtW5L3yYlj1Xz34c71rfKelQeL14kJY/+pIP7VTW02yr5Pf8GMCDH9BjwsW6OdUMp7GN53Gc62pGUVF8F/jnH86Xcbh3Hnq2AvXL7DwbuAL5f7biZhzcjJa7xOea98vDgQpwdx49x+f1daZPRrqQM3vGJ+4/Al6s1Tm640yl8uu3soFvZqBXTTgBu6GLj+lbF/O8n7cwf7mI9XmLJ2dxplW8ISyejacBxhWlb5w2mY6cKlv6E/2fgoCrL7EfawUYWxh0D3NZZu1Rpt8XAmoVxVwP/QToovk7hwEL6FPZ4oezb5INFtR2FlIT+XLHMu1hyBnIb8M0qO/o/FIZnAKcUhr9LYeepKDsaeKmizb9eGD4OuDm//rfiNlCYp8v1rjL/VOBLnUyraRsEPkr6ELEzFZ/GScn6GGCdrrZ5uk5G5wNnVJR/CPhIIc4ju9hOlOMYl4c/x5Iz361I+8aepO8xutrXLyUfqPPwWqQzuiE17lN3dFN/tf26pm0J+CbpQ91WXS2jUG/xeFH8MD0eeLCGdvsg8GRFvf8G/Di/7uxYN5Suk9Gngbsq3runittGRX37Afd2ts2Sznp/UmWbP4L0ga7y+PEzakhGTdkfHxF/IJ2mTshXqHyAtELVHEVKDA9Kmi5p31qWIen9kn4p6TlJrwL/RfoEUUvZdUkb6X9ExO8L40+S9ICkVyS9TPqkVVOdpE9GTxSGnyAloo0L44pXv71B2nErbUj6VFVZ12Y1xgHp4P16RflNSZ+a1gBmSHo5r+PNeXyH+RHxVhd1V65ntfieqlJuXuH1m1WG1wKQtIakH0l6Ir+vdwDrSepXmL+zdhxCOmuqVMt6F3VWz1K62gYj4rek7o3zgHmSLpS0Ti76SdIB7glJt0vapbtlVbEFcFLH+uR1GkJ6fzpUex/I8QVwFeksEuAQ0hkAkS76OYGULJ6XdJWkTavVU7mciFhIOqvYFGrap5aKscb9uqZtCfhvUm/FLZIek3RqF+tQqeo21lW7kd6TTSvek6+x5BiwXMc6UlsW2zhI3ekASNoov0dP5za7gq6PW1sAB1TEuSuwSV5WteNHt5oyGWWXkzL64cAtETGv2kwR8UhEHAxsROoeulbSmqRPsmt0zJcPRsWDx/nAg6Qr5tYhvemVF00sI3+h/jPgdxHxo8L4D5M+MfwLsH5ErEc6u+uoM7qp+hnSm9yh4xNG1fXuwgukM6rKup7uQR3r5zYsln8m1/0msF1ErJf/1o2IYlLs6XpWi6+7OrpyEums8oP5fR2Xx3f73pJ22OFVxtey3rXUU6nLbTAi/icidiJ1J70fODmPnx4RE0jb/C9IZ6499RRwZmF91ouINSLiysI83b0PVwKfkrQF6VP9dYXYfxYRu5Le6yDtm50Z0vFC0lqkrtBnatinqsW4XPt1NRHxWkScFBFbAh8HTpS0x/LUVaGzdnuKdLZdfE/WjojxOZ7OjnXdvU/PAi0dA/nisJbC9G/nOkblNjuMrtv4KdKZUTHONSNiUl5WteNHt5o9Ge1JOo29rLOZJB0maXBEvEv6Mg3Saf7DwEBJ/5QvL/46qQ+zw9qkftSFkrYBjq0xrjOBNUn9rkVrk5LHfKC/pG+Q+qU7zAOGdnF12JXAlyUNyzvkfwE/jx5ePRgR75AOTmdKWjtv8CeSPu30xOmSBuQDwr7ANbmNLwK+J2kjAEmbSfpYD+q9CXi/pEMk9Zd0IDCS9EVxb1iblDhelrQB8J89KPtTYE9J/5JjGyRp9HKs92TgK5J2ylcEbpXfh2qxVt0GJX1A0gfztvs66UKEd/J7cqikdSNiUS7/Tg/WscNFwMS8DElaM+8ra9daQUTcS9reJwNTI+LlHPvWkj4qabUc95vdxDhe0q6SBpAuKPhTRDxF9/tUNcu7Xy9D0r75vRNL2nl52nopnbUbqev9VUmnSFpdUj9J20v6QI6ns2PdfNJFBp39zulXwP+TtJ/SFYefB95XmL426eKElyVtRv7QUzCvou4rgI9L+liOcaCk3SS1RMQTpIssOo4fu5ISebeaNhlFxFzS1Rprkr5w7MzewGxJC0lffh4UEW9FxCuk7wMmkz51v07h1BT4CukU+TXSjvnzGkM7mNSP/5LSD90WSjqU1Gf6a1ISfIK0Exa7EK7J/xdIuqdKvZeQrly5g3QVzVvAF2qMqdIXSOv7GPAH0pncJT0o/xypb/4Z0gF6YkQ8mKedQuq6uDuf0t9KOhOpSUQsICW3k0hfen4V2DciXuhBfF35PumL7BeAu0ndabXG9iSp++skUlfRTNLFItCD9Y6Ia0gfWn5G2r5+Qfq0X6mrbXCdPO4l0va0gHQ1H6Tegrk5jomkT7I9EhFtpA96P8jLmEP6nqGnriR9aCx2o68GTCK9B8+RPsl/rYs6fkb60PAi6QKEQ/P47vapapZ3v65mBOl9Xkj6XvOHEXHbCtRXtEy75Q+SHyd9z/k4qf0mk7omofNj3RvkK1Bzt9nOxQXlfesA4CzSdjSSlDD+lmc5nXRByyukxHV9RazfBr6e6/5K/qAwgfSezie9JyezJJ8cQjrje5H0vl5eS4M03Y9erVxKd7a4IiJaupvXbEVJupR00cXXy46lr8i9M+2kn2z8rux4OjTtmZGZmfWO3KW2Xu467fge7e6Sw1qKk5GZ2XvfLqQrPF8gdQXuFxFvlhvS0txNZ2ZmpfOZkZmZla6uNxaUtDfpqo9+pF8kT6qYPoF0Kee7pEs4T8g/eEXSJaSrrp6PiO0LZU4jXQU0P4/6WkTc1FUcG264YQwdOrQ3VsnMrM+YMWPGCxHR2Y+7e1Xduunyj0wfJt23qJ10Q8yDI+KvhXnWAl6PiJA0Crg6IrbJ08aRLqm8vEoyWhgRZ1Oj1tbWaGtr64W1MjPrOyTNiIjWRiyrnt10Y4E5EfFYRLxNugXGhOIMEbEwlmTDpX5JHBF3kK5TNzOz97h6JqPNWPoHau1UuT+apP0lPUj6sdWRNdZ9vKRZki6RtH61GSQdLalNUtv8+fOrzWJmZk2insmo2v2glukTjIgbctfcfqTvj7pzPum+X6NJ90H6brWZIuLCiGiNiNbBgxvS5WlmZsupnhcwtFO4ASLpxnzPdDZzRNwhabikDbu6NUzxhqmSLqL37mlmZn3IokWLaG9v5623urrJfN8wcOBAWlpaWHXVVUuLoZ7JaDowQtIw0r3hDiLds+jvJG0FPJovYBhDevTBgq4qlbRJRDybB/cH7u/1yM3sPa+9vZ21116boUOHku6F2jdFBAsWLKC9vZ1hw4aVFkfdklFELJZ0POlmh/2ASyJitqSJefoFpOeyfFrSItKdfQ/suKBB0pWkh4VtKKkd+M+IuBg4S9JoUpffXNJDxszMeuStt97q84kIQBKDBg2i7O/W6/o7o/z7n5sqxl1QeP0dOnnOSX5uR7Xxh/dmjGbWd/X1RNShGdrBd2AwM7PSORmZmZVkrbWWfVjwHXfcwZgxY+jfvz/XXnttCVGVw8nIzKyJbL755lx66aUccsgh3c/8HlLX74zMzKxnOu6jucoqfetcwcnIzPq8E24+gZnPzezVOke/bzTf3/v7vVrne1nfSr1mZtaUfGZkZn2ez2DK5zMjMzMrnZORmVlJ3njjDVpaWv7+d8455zB9+nRaWlq45pprOOaYY9huu+3KDrMh3E1nZlaSd999t+r49vb2BkdSPp8ZmZlZ6ZyMzMysdE5GZmZWOicjMzMrnZORmZmVzsnIzMxK52RkZlaSao+QOOeccxg5ciSjRo1ijz324IknnighssZzMjIzayI77rgjbW1tzJo1i0996lN89atfLTukhnAyMjNrIrvvvjtrrLEGADvvvHOf+QGs78BgZjbjBHipdx8hwfqjYacVuwHrxRdfzD777NNLATU3JyMzsyZ0xRVX0NbWxu233152KA3hZGRmtoJnML3t1ltv5cwzz+T2229ntdVWKzuchnAyMjNrIvfeey/HHHMMN998MxtttFHZ4TSMk5GZWUk6HiHR4cQTT+Smm25i4cKFHHDAAQBsvvnmTJkypawQG6auyUjS3sC5QD9gckRMqpg+ATgDeBdYDJwQEX/I0y4B9gWej4jtC2U2AH4ODAXmAv8SES/Vcz3MzOqh2iMkTjzxxBIiKV/dLu2W1A84D9gHGAkcLGlkxWzTgB0iYjRwJDC5MO1SYO8qVZ8KTIuIEbn8qb0cupmZNVg9f2c0FpgTEY9FxNvAVcCE4gwRsTAiIg+uCURh2h3Ai1XqnQBcll9fBuzX24GbmVlj1TMZbQY8VRhuz+OWIml/SQ8CvyKdHXVn44h4FiD/r/oNn6SjJbVJaps/f36Pgzczs8apZzJSlXGxzIiIGyJiG9IZzhm9tfCIuDAiWiOidfDgwb1VrZmZ1UE9k1E7MKQw3AI809nMuVtuuKQNu6l3nqRNAPL/51c0UDMzK1c9k9F0YISkYZIGAAcBS12fKGkrScqvxwADgAXd1DsFOCK/PgK4sVejNjOzhqtbMoqIxcDxwFTgAeDqiJgtaaKkiXm2TwL3S5pJuvLuwI4LGiRdCdwFbC2pXdJRucwkYC9JjwB75WEzs5VOtUdI3HHHHYwZM4b+/ftz7bXXLjXtkUceYezYsYwaNYo999xzqWm33XYb++677zL1HXrooWy99dZsv/32HHnkkSxatKh3V6KX1PV3RhFxE3BTxbgLCq+/A3ynk7IHdzJ+AbBHL4ZpZtY0Nt98cy699FLOPvvsZaZNmjSJY489ls9+9rM8/vjjNdV36KGHcsUVVwBwyCGHMHnyZI499thejbk3+A4MZmZNZOjQoQCsssqyHVcDBgz4+yMlhg0bVlN948eP//vrsWPHNu0jKZyMzKzPO+EEmNnLT5AYPRq+38v3Xx0+fDiTJk1ixx13rNol15VFixbxk5/8hHPPPbd3g+olfriemdlK4J577uGmm27i3nvv5eSTT+bOO+8kIthyyy1Zcu+Azh133HGMGzeOD3/4ww2Itud8ZmRmfV5vn8HUw6233sq4ceMYMmQIN9xwA5/4xCeYOHEi48ePJ1+U3KnTTz+d+fPn86Mf/ahB0facz4zMzFYCO+64IzfeeCOvvPIK22yzDSeffDInnXQShx12WJflJk+ezNSpU7nyyiurfg/VLJo3MjOz97iOR0h0/J1zzjlMnz6dlpYWrrnmGo455hi22247APbaay8OO+wwdt55Z3baaSemTp3Kj3/8Yz7zmc/QccuzadOmLVXfXXfdxcSJE5k3bx677LILo0eP5pvf/GaZq9wp1dLXuLJrbW2Ntra2ssMwsybywAMPsO2225YdRtOo1h6SZkREayOW7zMjMzMrnZORmZmVzsnIzPqsvvA1RS2aoR2cjMysTxo4cCALFixoigNxmSKCBQsWMHDgwFLj8O+MzKxPamlpob29HT98MyXmlpaWUmNwMjKzPmnVVVet+f5uVn/upjMzs9I5GZmZWemcjMzMrHRORmZmVjonIzMzK52TkZmZlc7JyMzMSudkZGZmpXMyMjOz0jkZmZlZ6ZyMzMysdHVNRpL2lvSQpDmSTq0yfYKkWZJmSmqTtGt3ZSWdJunpXGampPH1XAczM6u/ut0oVVI/4DxgL6AdmC5pSkT8tTDbNGBKRISkUcDVwDY1lP1eRJxdr9jNzKyx6nlmNBaYExGPRcTbwFXAhOIMEbEwljxMZE0gai1rZmbvHfVMRpsBTxWG2/O4pUjaX9KDwK+AI2sse3zu3rtE0vrVFi7p6Nz11+bnlZiZNbd6JiNVGbfMIxUj4oaI2AbYDzijhrLnA8OB0cCzwHerLTwiLoyI1ohoHTx4cE9jNzOzBqpnMmoHhhSGW4BnOps5Iu4AhkvasKuyETEvIt6JiHeBi0hdemZmthKrZzKaDoyQNEzSAOAgYEpxBklbSVJ+PQYYACzoqqykTQpV7A/cX8d1MDOzBqjb1XQRsVjS8cBUoB9wSUTMljQxT78A+CTwaUmLgDeBA/MFDVXL5qrPkjSa1G03FzimXutgZmaNoSUXs713tba2RltbW9lhmJmtVCTNiIjWRizLd2AwM7PSORmZmVnpnIzMzKx0TkZmZlY6JyMzMyudk5GZmZXOycjMzErnZGRmZqVzMjIzs9I5GZmZWemcjMzMrHRORmZmVjonIzMzK52TkZmZla7bZCRpX0lOWmZmVje1JJmDgEcknSVp23oHZGZmfU+3ySgiDgN2BB4FfizpLklHS1q77tGZmVmfUFP3W0S8ClwHXAVsAuwP3CPpC3WMzczM+ohavjP6uKQbgN8CqwJjI2IfYAfgK3WOz8zM+oD+NcxzAPC9iLijODIi3pB0ZH3CMjOzvqSWZPSfwLMdA5JWBzaOiLkRMa1ukZmZWZ9Ry3dG1wDvFobfyePMzMx6RS3JqH9EvN0xkF8PqF9IZmbW19SSjOZL+kTHgKQJwAv1C8nMzPqaWpLRROBrkp6U9BRwCnBMLZVL2lvSQ5LmSDq1yvQJkmZJmimpTdKu3ZWVtIGk30h6JP9fv5ZYzMysedXyo9dHI2JnYCQwMiI+FBFzuisnqR9wHrBPLnuwpJEVs00DdoiI0cCRwOQayp4KTIuIEbn8MknOzMxWLrVcTYekfwK2AwZKAiAivtlNsbHAnIh4LNdxFTAB+GvHDBGxsDD/mkDUUHYCsFue7zLgNtLZmpmZraRq+dHrBcCBwBcAkX53tEUNdW8GPFUYbs/jKuvfX9KDwK9IZ0fdld04Ip4FyP836iTuo3PXX9v8+fNrCNfMzMpSy3dGH4qITwMvRcTpwC7AkBrKqcq4WGZExA0RsQ2wH3BGT8p2JSIujIjWiGgdPHhwT4qamVmD1ZKM3sr/35C0KbAIGFZDuXaWTlotwDOdzZzv8DBc0obdlJ0naROA/P/5GmIxM7MmVksy+j9J6wH/DdwDzAWurKHcdGCEpGGSBpAeRTGlOIOkrZS/hJI0hvT7pQXdlJ0CHJFfHwHcWEMsZmbWxLq8gCE/VG9aRLwMXCfpl8DAiHilu4ojYrGk44GpQD/gkoiYLWlinn4B8Eng05IWAW8CB0ZEAFXL5qonAVdLOgp4kvQdlpmZrcSUjv1dzCDdFRG7NCieumhtbY22traywzAzW6lImhERrY1YVi2Xdt8i6ZPA9dFd5nqP+dS+P2Xuo7VcOGhm1pyGDn+Ca395aNlhdKuWZHQi6TdAiyW9RbrSLSJinbpGZmZmfUa3ySgi+uzjxVeGTxNmZl3btftZmkC3yUjSuGrjKx+2Z2Zmtrxq6aY7ufB6IOlWPTOAj9YlIjMz63Nq6ab7eHFY0hDgrLpFZGZmfU4tP3qt1A5s39uBmJlZ31XLd0b/y5L7wq0CjAbuq2dQZmbWt9TynVHx16KLgSsj4o91isfMzPqgWpLRtcBbEfEOpAffSVojIt6ob2hmZtZX1PKd0TRg9cLw6sCt9QnHzMz6olqS0cDiE1nz6zXqF5KZmfU1tSSj1/PjHQCQtBPpDttmZma9opbvjE4ArpHU8XC7TUiPITczM+sVtfzodbqkbYCtSTdJfTAiFtU9MjMz6zO67aaT9HlgzYi4PyL+Aqwl6bj6h2ZmZn1FLd8ZfS4/6RWAiHgJ+Fz9QjIzs76mlmS0iiR1DEjqBwyoX0hmZtbX1HIBw1TgakkXkG4LNBH4dV2jMjOzPqWWZHQKcDRwLOkChntJV9SZmZn1im676SLiXeBu4DGgFdgDeKDOcZmZWR/S6ZmRpPcDBwEHAwuAnwNExO6NCc3MzPqKrrrpHgR+D3w8IuYASPpyQ6IyM7M+patuuk8CzwG/k3SRpD1I3xmZmZn1qk6TUUTcEBEHAtsAtwFfBjaWdL6kf6ylckl7S3pI0hxJp1aZfqikWfnvTkk7FKZ9SdL9kmZLOqEw/jRJT0uamf/G92B9zcysCdVyAcPrEfHTiNgXaAFmAssklkr590jnAfsAI4GDJY2smO1x4CMRMQo4A7gwl92e9MPascAOwL6SRhTKfS8iRue/m7qLxczMmlstP3r9u4h4MSJ+FBEfrWH2scCciHgsIt4GrgImVNR3Z76jA6Qr9lry622BuyPijYhYDNwO7N+TWM3MbOXRo2TUQ5sBTxWG2/O4zhzFkh/T3g+MkzRI0hrAeGBIYd7jc9feJZLWr1aZpKMltUlqmz9//vKvhZmZ1V09k1G1ix2i6ozS7qRkdApARDwAfAf4DXAzcB+wOM9+PjAcGA08C3y3Wp0RcWFEtEZE6+DBg1dgNczMrN7qmYzaWfpspgV4pnImSaOAycCEiFjQMT4iLo6IMRExDngReCSPnxcR7+Qf415E6g40M7OVWD2T0XRghKRhkgaQfkA7pTiDpM2B64HDI+LhimkbFeb5Z+DKPFy8FdH+pC49MzNbidVyb7rlEhGLJR1PutFqP+CSiJgtaWKefgHwDWAQ8MN8Y/DFEdGaq7hO0iBgEfD5woUOZ0kaTerymwscU691MDOzxlBE1a9x3lNaW1ujra2t7DDMzFYqkmYUThDqqp7ddGZmZjVxMjIzs9I5GZmZWemcjMzMrHRORmZmVjonIzMzK52TkZmZlc7JyMzMSudkZGZmpXMyMjOz0jkZmZlZ6ZyMzMysdE5GZmZWOicjMzMrnZORmZmVzsnIzMxK52RkZmalczIyM7PSORmZmVnpnIzMzKx0TkZmZlY6JyMzMyudk5GZmZXOycjMzEpX12QkaW9JD0maI+nUKtMPlTQr/90paYfCtC9Jul/SbEknFMZvIOk3kh7J/9ev5zqYmVn91S0ZSeoHnAfsA4wEDpY0smK2x4GPRMQo4Azgwlx2e+BzwFhgB2BfSSNymVOBaRExApiWh83MbCVWzzOjscCciHgsIt4GrgImFGeIiDsj4qU8eDfQkl9vC9wdEW9ExGLgdmD/PG0CcFl+fRmwXx3XwczMGqCeyWgz4KnCcHse15mjgF/n1/cD4yQNkrQGMB4YkqdtHBHPAuT/G1WrTNLRktoktc2fP38FVsPMzOqtfx3rVpVxUXVGaXdSMtoVICIekPQd4DfAQuA+YHFPFh4RF5K7/VpbW6su18zMmkM9z4zaWXI2A6kL7pnKmSSNAiYDEyJiQcf4iLg4IsZExDjgReCRPGmepE1y2U2A5+sUv5mZNUg9k9F0YISkYZIGAAcBU4ozSNocuB44PCIerpi2UWGefwauzJOmAEfk10cAN9ZtDczMrCHq1k0XEYslHQ9MBfoBl0TEbEkT8/QLgG8Ag8ttgd4AAAoHSURBVIAfSgJYHBGtuYrrJA0CFgGfL1zoMAm4WtJRwJPAAfVaBzMzawxFvPe/TmltbY22traywzAzW6lImlE4Qagr34HBzMxK52RkZmalczIyM7PSORmZmVnpnIzMzKx0TkZmZlY6JyMzMyudk5GZmZXOycjMzErnZGRmZqVzMjIzs9I5GZmZWemcjMzMrHRORmZmVjonIzMzK52TkZmZlc7JyMzMSudkZGZmpXMyMjOz0jkZmZlZ6ZyMzMysdE5GZmZWOicjMzMrnZORmZmVrq7JSNLekh6SNEfSqVWmHyppVv67U9IOhWlfljRb0v2SrpQ0MI8/TdLTkmbmv/H1XAczM6u/uiUjSf2A84B9gJHAwZJGVsz2OPCRiBgFnAFcmMtuBnwRaI2I7YF+wEGFct+LiNH576Z6rYOZmTVGPc+MxgJzIuKxiHgbuAqYUJwhIu6MiJfy4N1AS2Fyf2B1Sf2BNYBn6hirmZmVqJ7JaDPgqcJwex7XmaOAXwNExNPA2cCTwLPAKxFxS2He43PX3iWS1q9WmaSjJbVJaps/f/6KrIeZmdVZPZORqoyLqjNKu5OS0Sl5eH3SWdQwYFNgTUmH5dnPB4YDo0mJ6rvV6oyICyOiNSJaBw8evCLrYWZmdVbPZNQODCkMt1Clq03SKGAyMCEiFuTRewKPR8T8iFgEXA98CCAi5kXEOxHxLnARqTvQzMxWYvVMRtOBEZKGSRpAugBhSnEGSZuTEs3hEfFwYdKTwM6S1pAkYA/ggVxmk8J8+wP313EdzMysAfrXq+KIWCzpeGAq6Wq4SyJitqSJefoFwDeAQcAPU85hce5a+5Oka4F7gMXAveQr7YCzJI0mdfnNBY6p1zqYmVljKKLq1zjvKa2trdHW1lZ2GGZmKxVJMyKitRHL8h0YzMysdE5GZmZWOicjMzMrnZORmZmVzsnIzMxK52RkZmalczIyM7PSORmZmVnpnIzMzKx0TkZmZlY6JyMzMytdn7g3naT5wBPLUXRD4IVeDqc3Ob4V4/hWjONbMStDfGtGREMeCNcnktHyktTWqJsELg/Ht2Ic34pxfCvG8S3N3XRmZlY6JyMzMyudk1HXLux+llI5vhXj+FaM41sxjq/A3xmZmVnpfGZkZmalczIyM7PS9ZlkJGlvSQ9JmiPp1CrTJel/8vRZksZ0V1bSBpJ+I+mR/H/9RscnaYik30l6QNJsSV8qlDlN0tOSZua/8Y2OL0+bK+kvOYa2wvhmaL+tC+0zU9Krkk7I0xrZfttIukvS3yR9pZayDW6/qvE10fbXVfs1w/bXWfs1y/Z3aN4vZkm6U9IO3ZXtzfYDICLe839AP+BRYEtgAHAfMLJinvHArwEBOwN/6q4scBZwan59KvCdEuLbBBiTX68NPFyI7zTgK2W2X542F9iwSr2lt1+Vep4Dtiih/TYCPgCcWVxmE21/ncXXLNtf1fiaaPvrNL4m2f4+BKyfX+9DA49/HX995cxoLDAnIh6LiLeBq4AJFfNMAC6P5G5gPUmbdFN2AnBZfn0ZsF+j44uIZyPiHoCIeA14ANhsOePo9fi6qbf09quYZw/g0YhYnrt1rFB8EfF8REwHFvWgbMPar7P4mmX766L9ulJ6+1Uoc/u7MyJeyoN3Ay01lO2t9gP6TjfdZsBTheF2lt1hOpunq7IbR8SzkHZK0qefRsf3d5KGAjsCfyqMPj6fel+yAqfRKxpfALdImiHp6MI8TdV+wEHAlRXjGtV+y1O2ke3XrZK3v640w/ZXi2bZ/o4i9SJ0V7a32g/oO8lIVcZVXtPe2Ty1lF1RKxJfmiitBVwHnBARr+bR5wPDgdHAs8B3S4rvHyJiDOn0//OSxi1nHJ3pjfYbAHwCuKYwvZHtV4+ytVrhZTTB9teVZtj+uq6gSbY/SbuTktEpPS27ovpKMmoHhhSGW4Bnapynq7LzOrp68v/nS4gPSauSDgQ/jYjrO2aIiHkR8U5EvAtcRDrlbnh8EdHx/3nghkIcTdF+2T7APRExr2NEg9tveco2sv061STbX6eaZPvrTunbn6RRwGRgQkQsqKFsb7Uf0HeS0XRghKRh+RPIQcCUinmmAJ9WsjPwSj717KrsFOCI/PoI4MZGxydJwMXAAxFxTrFAxXci+wP3lxDfmpLWzvGsCfxjIY7S268w/WAqukga3H7LU7aR7VdVE21/ncXXLNtfd0rd/iRtDlwPHB4RD9dYtrfaL1mRqx9Wpj/S1VQPk64M+fc8biIwMb8WcF6e/hegtauyefwgYBrwSP6/QaPjA3YlnTbPAmbmv/F52k/yvLPyhrNJCfFtSboC5z5gdrO1X562BrAAWLeizka23/tIn0JfBV7Or9dpou2vanxNtP11Fl+zbH9dvb/NsP1NBl4qvIdtXZXt7faLCN8OyMzMytdXuunMzKyJORmZmVnpnIzMzKx0TkZmZlY6JyMzMyudk5H1aZLeJ+kqSY9K+qukmyS9fznr+oykH+TXEyV9ejnqWE/Sccuz/GZcjlmtnIysz8o/2LwBuC0ihkfESOBrwMYrWndEXBARly9H0fWARiSJRi3HrCZORtaX7Q4siogLOkZExMyI+H3ljJJ+kW+0Obt4s01Jn5X0sKTbgX8ojD9N+bk1km6T1Jpfbyhpbn69naQ/Kz2rZpakEcAkYHge99+SdpN0u6Sr83ImKT175s9Kz+gZnusaLOk6SdPz3z8U4rgkx/CYpC/mEJdaTq+2qtly6F92AGYl2h6YUeO8R0bEi5JWB6ZLuo70fJfTgZ2AV4DfAff2YPkTgXMj4qf5Viv9SM+F2T4iRgNI2g3YAdgWeBF4DJgcEWOVHmT3BeAE4FzgexHxh3xrl6m5DMA2pMS7NvCQpPMrl2NWNicjs9p8UdL++fUQYATpFi+3RcR8AEk/B3ryfdNdwL9LagGuj4hHUs/hMqZHvo+epEeBW/L4v5CSDMCewMhC+XU67skG/Coi/gb8TdLz9EI3pFlvczKyvmw28KnuZspnJ3sCu0TEG5JuAwbmybXcT2sxS7rEO8oRET+T9Cfgn4Cpkv6VdOZT6W+F1+8Wht9lyT68So7vzYrYK8u/g/d7a0L+zsj6st8Cq0n6XMcISR+Q9JGK+dYFXsqJaBvSY8shPURuN0mDlB6jcEAny5lL6sqDQvKTtCXwWET8D+lGmKOA10jdaT11C3B8oe7uut+WdzlmdeFkZH1WpLsE7w/slS/tng2cxrLPerkZ6C9pFnAG6bHM5K6z00jdbbcC91QuIv8/GzhW0p3AhoXpBwL3S5pJ+l7n8kjPkfmjpPt7eGHBF4HWfCHEX0nfR3VqBZZjVhe+a7dZHUj6X9LD0n5cdixmKwOfGZn1MklnAB+k5w9YM+uzfGZkZmal85mRmZmVzsnIzMxK52RkZmalczIyM7PSORmZmVnp/j8XQZA3WLxuDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lK-1_KPsl_DI"
      },
      "source": [
        "*Explain answer here*\n",
        "\n",
        "Our parameter selection does not seem to be justified. For all of our possibilites, we have have the same accuracy of less than 30%. This indicates our prediction task and methods did not work as planned. This could be do to the fact that there are so many different variables that go into whether a genetic variant actually is pathogenic or benign. While I do not believe we have data snooping because there really is not a big reveal or a significant finding, I do believe there is a serious issue with our task as well as with the analysis of the variables we are using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TBz7sp8ZefFf"
      },
      "source": [
        "### ***15 points***\n",
        "Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time and classification performance. Discuss the results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I0UThcgkmIef",
        "outputId": "84b0e853-90f6-40b9-891f-f916c3deb2b9",
        "colab": {}
      },
      "source": [
        "# visualize performance differences training time our best logistic regression optimization procedure\n",
        "# visualize performance classification our best logistic regression optimization procedure\n",
        "\n",
        "import time\n",
        "import sklearn\n",
        "startL2= time.time()\n",
        " \n",
        "bfgslr2 = BFGSBinaryLogisticRegressionL2(_,2,C=C_step) \n",
        "bfgslr2.fit(lr_data_X_train, lr_data_Y_train)\n",
        "yhat = bfgslr2.predict(lr_data_X_test)\n",
        "\n",
        "endL2= time.time()\n",
        "training_time_my_BFGSL2= endL2- startL2\n",
        "my_bfgslr2_accuracy = accuracy_score(lr_data_Y_test,yhat)\n",
        "print('My Training Time:', training_timeBFGSL2)\n",
        "print('My Accuracy:', my_accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My Training Time: 0.021033763885498047\n",
            "My Accuracy: 0.29896907216494845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cPHIsUQc8vo",
        "colab_type": "code",
        "outputId": "6c07569b-3e2a-4193-bf4c-773f2acd84fa",
        "colab": {}
      },
      "source": [
        "# visualize performance differences training time sci-kit learn\n",
        "# visualize performance classification sci-kit learn optimization procedure\n",
        "startL2= time.time()\n",
        "scikit_bfgslr2 = sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, \n",
        "                                        C=0.01, fit_intercept=True, \n",
        "                                        solver='lbfgs', max_iter=1000).fit(lr_data_X_train, lr_data_Y_train)\n",
        "yhat = scikit_bfgslr2.predict(lr_data_X_test)\n",
        "endL2= time.time()\n",
        "training_time_scikit_BFGSL2= endL2 - startL2\n",
        "scikit_bfgslr2_accuracy = accuracy_score(lr_data_Y_test,yhat)\n",
        "print('Scikit-learn training time:', training_time_scikit_BFGSL2)\n",
        "print('Scikit-learn accuracy:', scikit_bfgslr2_accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scikit-learn training time: 5.298713207244873\n",
            "Scikit-learn accuracy: 0.9925207196280574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfD14NZ3c8vr",
        "colab_type": "code",
        "outputId": "4767c291-7fe6-492c-c2c7-d5a343d4d0bd",
        "colab": {}
      },
      "source": [
        "plt.plot(training_time_my_BFGSL2, my_bfgslr2_accuracy, 'go', label=\"My BFGSL2\")\n",
        "plt.plot(training_time_scikit_BFGSL2, scikit_bfgslr2_accuracy, 'bs', label=\"Scikit Learn\")\n",
        "\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Visualization of performance differences and classification between our best logistic regression optimization and scikit-learn')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_RTMRwrFmkoY"
      },
      "source": [
        "*Explain answer here* <br/>\n",
        "Since performance doesnt change between values of C and regularization techniques, we choose BFGSBinaryLogisticRegressionL2 to compare with scikit-learn\n",
        "<br/><br/>\n",
        "From the visualization of performance and time, it is very obvious that scikit learn is much better than our technique. While our technique takes very little time, it is obvious that it was at the detriment of our performance. While our performance is around 30%, scikit learn's accuracy is close to 90-95%, which is the accuracy we originally wanted for our data. While scikit learn takes more time, this is not a huge issue as this is a system that would run in the background and not at a moment's notice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXOIO5H3dwfb"
      },
      "source": [
        "## Deployment [***10 points***]\n",
        "Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iJOPh7qSgb6x"
      },
      "source": [
        "*Explain answer here*\n",
        "\n",
        "Scikit learn is what I would suggest be used for this dataset. Our implementation does not find the best accuracy rates, they are around 30% which is no where near good enough to be used in any deployment for the medical field. Scikit learn is created to run these sort of calculations in a quick and correct manner. It has been created and refined more than our implementation, and thus would have a better accuracy than we will be able to reach in our implementation. Scikit learn was written by those with a deeper knowledge than us as well, and thus performs better. Our implementation does not do well for our classification task. I would not suggest our implementation. Scikit learn had the best accuracy, which is what matters for our dataset since it involves people and their health."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zyA7zZFidz6j"
      },
      "source": [
        "## Exceptional Work [***10 points***]\n",
        "You have free reign to provide additional analyses. One idea: Update the code to use either \"one-versus-all\" or \"one-versus-one\" extensions of binary to multi-class classification. One idea (required for 7000 level students): Implement an optimization technique for logistic regression using mean square error as your objective function (instead of binary entropy). Your solution should be able to solve the binary logistic regression problem in one update step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cciI8zEZc8vx",
        "colab_type": "code",
        "outputId": "d6fb6db3-4325-46c4-d2c8-146bf6ccda11",
        "colab": {}
      },
      "source": [
        "class MultiClassLogisticRegression:\n",
        "    def __init__(self, eta, iterations=20, C=0.0001):\n",
        "        self.eta = eta\n",
        "        self.iters = iterations\n",
        "        self.C = C\n",
        "        self.classifiers_ = []\n",
        "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
        "    \n",
        "    def __str__(self):\n",
        "        if(hasattr(self,'w_')):\n",
        "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
        "        else:\n",
        "            return 'Untrained MultiClass Logistic Regression Object'\n",
        "        \n",
        "    def fit(self,X,y):\n",
        "        num_samples, num_features = X.shape\n",
        "        self.unique_ = np.sort(np.unique(y)) # get each unique class value\n",
        "        num_unique_classes = len(self.unique_)\n",
        "        self.classifiers_ = []\n",
        "        for i,yval in enumerate(self.unique_): # for each unique value\n",
        "            y_binary = y==yval # create a binary problem\n",
        "            # train the binary classifier for this class\n",
        "            hblr = BFGSBinaryLogisticRegressionL2(self.eta,self.iters,self.C)\n",
        "            hblr.fit(X,y_binary)\n",
        "            #print(accuracy(y_binary,hblr.predict(X)))\n",
        "            # add the trained classifier to the list\n",
        "            self.classifiers_.append(hblr)\n",
        "        # save all the weights into one matrix, separate column for each class\n",
        "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
        "        \n",
        "    def predict_proba(self,X):\n",
        "        probs = []\n",
        "        for hblr in self.classifiers_:\n",
        "            probs.append(hblr.predict_proba(X).reshape((len(X),1))) # get probability for each classifier\n",
        "        \n",
        "        return np.hstack(probs) # make into single matrix\n",
        "    \n",
        "    def predict(self,X):\n",
        "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
        "    \n",
        "lr = MultiClassLogisticRegression(_,iterations=10,C=0.001)\n",
        "lr.fit(lr_data_X_train, lr_data_Y_train)\n",
        "print(lr)\n",
        "\n",
        "yhat = lr.predict(lr_data_X_test)\n",
        "print('Accuracy of: ',accuracy_score(lr_data_Y_test,yhat))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Skyler\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "C:\\Users\\Skyler\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MultiClass Logistic Regression Object with coefficients:\n",
            "[[-9.11825125e-01  2.89582045e-03 -2.42438456e-02 -2.58104660e-02\n",
            "   3.44926242e-01 -6.70948715e-01 -1.74369552e-01 -4.73912680e+00]\n",
            " [ 1.90027714e+00  1.66210495e-02  6.74284757e-02  6.78049161e-02\n",
            "  -2.16573934e-01  1.32948465e+00  1.84421063e-01  8.38275969e-01]\n",
            " [-8.01965604e+00  4.55615582e-03 -1.73492122e-01 -1.79333349e-01\n",
            "   1.16279020e-01 -5.93668553e+00 -1.45443650e+00  3.90610050e+00]\n",
            " [-6.77156446e-01 -6.91091717e-01 -1.16439156e-02 -1.18316729e-02\n",
            "  -8.22662046e-01 -5.17026464e-01 -1.70815981e-01 -1.28876995e+00]]\n",
            "Accuracy of:  0.02809783707297352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kmhljcDgS1L"
      },
      "source": [
        "The above code is for MultiClass Logistic Regression. Our version of MultiClass Regression is very bad when it comes to our dataset. As it is less than 3% accurate, this means that it would not be useful in any way, shape, or form. "
      ]
    }
  ]
}